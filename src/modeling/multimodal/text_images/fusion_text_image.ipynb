{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1c8677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "DATA_PATH = r\"D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\data\\training\\multimodal_splits\\text_image_dataset.csv\"\n",
    "\n",
    "TEXT_MODEL_PATH = r\"D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\text_baseline\\indobert-base-p1\"\n",
    "IMAGE_MODEL_PATH = r\"D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\image_baseline\\best_mobilenetv3_tf_style.pth\"\n",
    "\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3b81d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sample_id  label     data_source  confidence  sample_weight  \\\n",
      "0    NEWS_1  valid  original_valid         1.0            1.0   \n",
      "1    NEWS_2  valid  original_valid         1.0            1.0   \n",
      "2    NEWS_3  valid  original_valid         1.0            1.0   \n",
      "3    NEWS_4  valid  original_valid         1.0            1.0   \n",
      "4    NEWS_5  valid  original_valid         1.0            1.0   \n",
      "\n",
      "                                               title  \\\n",
      "0  Profil Menko Hukum HAM Yusril Ihza Mahendra di...   \n",
      "1  Profil Menteri PPPA Arifatul Choiri Fauzi di K...   \n",
      "2  Prabowo Tunjuk Yassierli Jadi Menteri Ketenaga...   \n",
      "3  Profil Yassierli, Menteri Ketenagakerjaan Kabi...   \n",
      "4  Apa yang Harus Dilakukan di Usia 30 Tahun untu...   \n",
      "\n",
      "                                        text_content  \\\n",
      "0  Profil Yusril Ihza Mahendra kembali menjadi so...   \n",
      "1  Profil Arifatul Choiri Fauzi menjadi sorotan s...   \n",
      "2  Presiden Prabowo Subianto menunjuk Guru Besar ...   \n",
      "3  , 20 Oktober 2024, 22:46 WIB Erwina Rachmi Pus...   \n",
      "4  Di usia 30-an tahun, kita bisa melakukan beber...   \n",
      "\n",
      "                   image_path               domain                 date  \\\n",
      "0  data/raw/news/images\\1.jpg  nasional.kompas.com  2024-10-19 17:00:00   \n",
      "1  data/raw/news/images\\2.jpg  nasional.kompas.com  2024-10-19 17:00:00   \n",
      "2  data/raw/news/images\\3.jpg  nasional.kompas.com  2024-10-19 17:00:00   \n",
      "3  data/raw/news/images\\4.jpg       www.kompas.com  2024-10-19 17:00:00   \n",
      "4  data/raw/news/images\\5.jpg    health.kompas.com  2024-10-20 15:00:00   \n",
      "\n",
      "   label_int  \n",
      "0          1  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n",
      "Total data: 3272\n",
      "Label distrib total:\n",
      " label_int\n",
      "1    2051\n",
      "0    1221\n",
      "Name: count, dtype: int64\n",
      "Train size: 2290\n",
      "label_int\n",
      "1    1435\n",
      "0     855\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Val size: 491\n",
      "label_int\n",
      "1    308\n",
      "0    183\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Test size: 491\n",
      "label_int\n",
      "1    308\n",
      "0    183\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "label_map = {\"hoax\": 0, \"valid\": 1}\n",
    "df[\"label_int\"] = df[\"label\"].map(label_map)\n",
    "\n",
    "print(df.head())\n",
    "print(\"Total data:\", len(df))\n",
    "print(\"Label distrib total:\\n\", df[\"label_int\"].value_counts())\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,                \n",
    "    stratify=df[\"label_int\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,                \n",
    "    stratify=temp_df[\"label_int\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "for name, part in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
    "    print(f\"{name} size: {len(part)}\")\n",
    "    print(part[\"label_int\"].value_counts(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cab1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(TEXT_MODEL_PATH)\n",
    "text_model = BertForSequenceClassification.from_pretrained(TEXT_MODEL_PATH).to(DEVICE)\n",
    "text_model.eval()\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = str(row[\"title\"])    \n",
    "        label = int(row[\"label_int\"])\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "def text_collate_fn(batch):\n",
    "    input_ids = torch.stack([b[\"input_ids\"] for b in batch])\n",
    "    attn = torch.stack([b[\"attention_mask\"] for b in batch])\n",
    "    labels = torch.stack([b[\"label\"] for b in batch])\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attn, \"label\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16ca3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],    \n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, img_size=(224, 224)):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform or (lambda x: x)\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        rel_path = row[\"image_path\"]     \n",
    "        img_path = os.path.join(\n",
    "            r\"D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\",\n",
    "            rel_path.lstrip(\"./\\\\\")\n",
    "        )\n",
    "        label = int(row[\"label_int\"])\n",
    "\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except (FileNotFoundError, OSError):\n",
    "            img = Image.new(\"RGB\", self.img_size, color=(128, 128, 128))\n",
    "\n",
    "        img_t = self.transform(img)\n",
    "        return {\"image\": img_t, \"label\": torch.tensor(label, dtype=torch.long)}\n",
    "\n",
    "def image_collate_fn(batch):\n",
    "    imgs = torch.stack([b[\"image\"] for b in batch])\n",
    "    labels = torch.stack([b[\"label\"] for b in batch])\n",
    "    return {\"image\": imgs, \"label\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4244e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text\n",
    "train_text_ds = TextDataset(train_df, tokenizer, MAX_LEN)\n",
    "val_text_ds   = TextDataset(val_df, tokenizer, MAX_LEN)\n",
    "test_text_ds  = TextDataset(test_df, tokenizer, MAX_LEN)\n",
    "\n",
    "train_text_loader = DataLoader(train_text_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=text_collate_fn)\n",
    "val_text_loader   = DataLoader(val_text_ds,   batch_size=BATCH_SIZE, shuffle=False, collate_fn=text_collate_fn)\n",
    "test_text_loader  = DataLoader(test_text_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=text_collate_fn)\n",
    "\n",
    "# Image\n",
    "train_img_ds = ImageDataset(train_df, transform=img_transform)\n",
    "val_img_ds   = ImageDataset(val_df,   transform=img_transform)\n",
    "test_img_ds  = ImageDataset(test_df,  transform=img_transform)\n",
    "\n",
    "train_img_loader = DataLoader(train_img_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=image_collate_fn)\n",
    "val_img_loader   = DataLoader(val_img_ds,   batch_size=BATCH_SIZE, shuffle=False, collate_fn=image_collate_fn)\n",
    "test_img_loader  = DataLoader(test_img_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=image_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d7f8240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16244\\757619158.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  img_state = torch.load(IMAGE_MODEL_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Conv2dNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_mobilenetv3_tf_style(num_classes=2):\n",
    "   \n",
    "    model = models.mobilenet_v3_small(weights=None)\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "image_model = create_mobilenetv3_tf_style(num_classes=2)\n",
    "img_state = torch.load(IMAGE_MODEL_PATH, map_location=DEVICE)\n",
    "image_model.load_state_dict(img_state)\n",
    "image_model.to(DEVICE)\n",
    "image_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b826a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_probs(loader):\n",
    "    all_probs = []\n",
    "    text_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attn = batch[\"attention_mask\"].to(DEVICE)\n",
    "            outputs = text_model(input_ids=input_ids, attention_mask=attn)\n",
    "            logits = outputs.logits\n",
    "            probs = softmax(logits, dim=-1)[:, 0]  # prob hoax\n",
    "            all_probs.extend(probs.cpu().numpy().tolist())\n",
    "    return np.array(all_probs)\n",
    "\n",
    "def get_image_probs(loader):\n",
    "    all_probs = []\n",
    "    image_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            imgs = batch[\"image\"].to(DEVICE)\n",
    "            logits = image_model(imgs)\n",
    "            probs = softmax(logits, dim=-1)[:, 0]  # prob hoax\n",
    "            all_probs.extend(probs.cpu().numpy().tolist())\n",
    "    return np.array(all_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2fea0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob\n",
    "p_text_train = get_text_probs(train_text_loader)\n",
    "p_text_val   = get_text_probs(val_text_loader)\n",
    "p_text_test  = get_text_probs(test_text_loader)\n",
    "\n",
    "p_img_train = get_image_probs(train_img_loader)\n",
    "p_img_val   = get_image_probs(val_img_loader)\n",
    "p_img_test  = get_image_probs(test_img_loader)\n",
    "\n",
    "y_train = train_df[\"label_int\"].to_numpy()\n",
    "y_val   = val_df[\"label_int\"].to_numpy()\n",
    "y_test  = test_df[\"label_int\"].to_numpy()\n",
    "\n",
    "def evaluate_probs(p_hoax, y_true, thr=0.5):\n",
    "    y_pred = np.where(p_hoax >= thr, 0, 1)  # 0=hoax,1=valid\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1_hoax = f1_score(y_true, y_pred, pos_label=0)\n",
    "    f1_valid = f1_score(y_true, y_pred, pos_label=1)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    return acc, f1_hoax, f1_valid, f1_macro\n",
    "\n",
    "def fusion_two(p_a, p_b, alpha):\n",
    "    return alpha * p_a + (1 - alpha) * p_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a15e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alpha_text       acc   f1_hoax  f1_valid  f1_macro\n",
      "2         0.2  0.971487  0.961538  0.977346  0.969442\n",
      "4         0.4  0.971487  0.961326  0.977419  0.969373\n",
      "1         0.1  0.969450  0.958678  0.975767  0.967223\n",
      "3         0.3  0.969450  0.958678  0.975767  0.967223\n",
      "5         0.5  0.969450  0.958217  0.975923  0.967070\n",
      "Best alpha_text (text+image): 0.2\n"
     ]
    }
   ],
   "source": [
    "alphas = np.linspace(0, 1, 11)\n",
    "\n",
    "records_ti = []\n",
    "for a in alphas:\n",
    "    p_ti_val = fusion_two(p_text_val, p_img_val, a)\n",
    "    acc, f1h, f1v, f1m = evaluate_probs(p_ti_val, y_val)\n",
    "    records_ti.append((a, acc, f1h, f1v, f1m))\n",
    "\n",
    "df_ti = pd.DataFrame(records_ti, columns=[\"alpha_text\", \"acc\", \"f1_hoax\", \"f1_valid\", \"f1_macro\"])\n",
    "print(df_ti.sort_values(\"f1_macro\", ascending=False).head())\n",
    "\n",
    "best_row_ti = df_ti.sort_values(\"f1_macro\", ascending=False).iloc[0]\n",
    "alpha_text_best = float(best_row_ti[\"alpha_text\"])\n",
    "print(\"Best alpha_text (text+image):\", alpha_text_best)\n",
    "\n",
    "p_ti_test = fusion_two(p_text_test, p_img_test, alpha_text_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab7bec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Results (Text+Image) ===\n",
      "Text      : acc=0.9348 f1h=0.9086 f1v=0.9494 f1m=0.9290\n",
      "Image     : acc=0.9491 f1h=0.9304 f1v=0.9599 f1m=0.9451\n",
      "Text+Img  : acc=0.9572 f1h=0.9412 f1v=0.9664 f1m=0.9538\n",
      "\n",
      "Classification report (Text+Img):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9655    0.9180    0.9412       183\n",
      "           1     0.9527    0.9805    0.9664       308\n",
      "\n",
      "    accuracy                         0.9572       491\n",
      "   macro avg     0.9591    0.9493    0.9538       491\n",
      "weighted avg     0.9575    0.9572    0.9570       491\n",
      "\n",
      "Confusion matrix:\n",
      " [[168  15]\n",
      " [  6 302]]\n"
     ]
    }
   ],
   "source": [
    "# Text-only\n",
    "acc_t, f1h_t, f1v_t, f1m_t = evaluate_probs(p_text_test, y_test)\n",
    "\n",
    "# Image-only\n",
    "acc_i, f1h_i, f1v_i, f1m_i = evaluate_probs(p_img_test, y_test)\n",
    "\n",
    "# Text+Image\n",
    "acc_ti, f1h_ti, f1v_ti, f1m_ti = evaluate_probs(p_ti_test, y_test)\n",
    "\n",
    "print(\"=== Test Results (Text+Image) ===\")\n",
    "print(\"Text      : acc={:.4f} f1h={:.4f} f1v={:.4f} f1m={:.4f}\".format(acc_t,  f1h_t,  f1v_t,  f1m_t))\n",
    "print(\"Image     : acc={:.4f} f1h={:.4f} f1v={:.4f} f1m={:.4f}\".format(acc_i,  f1h_i,  f1v_i,  f1m_i))\n",
    "print(\"Text+Img  : acc={:.4f} f1h={:.4f} f1v={:.4f} f1m={:.4f}\".format(acc_ti, f1h_ti, f1v_ti, f1m_ti))\n",
    "\n",
    "print(\"\\nClassification report (Text+Img):\")\n",
    "y_pred_ti = np.where(p_ti_test >= 0.5, 0, 1)\n",
    "print(classification_report(y_test, y_pred_ti, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_ti))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af714fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved text+image fusion model to: D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\fusion_final\\2text_image_late_fusion_a0.20.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "class TextImageLateFusion:\n",
    "    def __init__(self, alpha_text=0.0):\n",
    "        self.alpha_text = float(alpha_text)\n",
    "        self.alpha_img = 1.0 - float(alpha_text)\n",
    "\n",
    "    def fusion(self, p_text_hoax, p_img_hoax):\n",
    "        p_hoax = self.alpha_text * p_text_hoax + self.alpha_img * p_img_hoax\n",
    "        p_valid = 1.0 - p_hoax\n",
    "        return np.vstack([p_hoax, p_valid]).T\n",
    "\n",
    "    def predict(self, p_text_hoax, p_img_hoax, thr=0.5):\n",
    "        probs = self.fusion(p_text_hoax, p_img_hoax)\n",
    "        return (probs[:, 0] < thr).astype(int)\n",
    "\n",
    "fusion_ti = TextImageLateFusion(alpha_text=alpha_text_best)\n",
    "fname = rf\"D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\fusion_final\\text_image_late_fusion_a{alpha_text_best:.2f}.joblib\"\n",
    "joblib.dump(fusion_ti, fname)\n",
    "print(\"Saved text+image fusion model to:\", fname)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
