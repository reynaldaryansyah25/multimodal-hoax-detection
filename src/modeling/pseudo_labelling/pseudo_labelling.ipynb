{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fa5906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PSEUDO-LABELING DATA YOUTUBE DENGAN BALANCED STRATEGY\n",
      "================================================================================\n",
      "\n",
      "Library berhasil diimport\n",
      "PyTorch version: 2.1.0+cu118\n",
      "CUDA tersedia: True\n",
      "Device yang akan digunakan: GPU\n",
      "\n",
      "Setup selesai. Siap untuk tahap berikutnya.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PSEUDO-LABELING DATA YOUTUBE DENGAN BALANCED STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nLibrary berhasil diimport\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA tersedia: {torch.cuda.is_available()}\")\n",
    "print(f\"Device yang akan digunakan: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(\"\\nSetup selesai. Siap untuk tahap berikutnya.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9043fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEMUAT MODEL INDOBERT\n",
      "================================================================================\n",
      "\n",
      "Memuat model dari:\n",
      "  D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\pseudo_labelling\\indobert_title_model\n",
      "\n",
      "Model berhasil dimuat\n",
      "Device: cuda\n",
      "Jumlah parameter: 110,559,746\n",
      "Status: Evaluation mode (siap untuk prediksi)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEMUAT MODEL INDOBERT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Path model (sesuaikan dengan lokasi Anda)\n",
    "model_path = r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\pseudo_labelling\\indobert_title_model'\n",
    "\n",
    "print(f\"\\nMemuat model dari:\")\n",
    "print(f\"  {model_path}\")\n",
    "\n",
    "# Load tokenizer dan model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\nModel berhasil dimuat\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Jumlah parameter: {model.num_parameters():,}\")\n",
    "print(f\"Status: Evaluation mode (siap untuk prediksi)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2caec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEMUAT DATA YOUTUBE\n",
      "================================================================================\n",
      "\n",
      "Membaca file:\n",
      "  D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\data\\normalization\\metadata_yt.json\n",
      "\n",
      "Total data YouTube: 992 video\n",
      "\n",
      "Info dataset:\n",
      "  Total records: 992\n",
      "  Total kolom: 25\n",
      "\n",
      "Kolom yang tersedia:\n",
      "   1. sample_id\n",
      "   2. source\n",
      "   3. keyword\n",
      "   4. video_id\n",
      "   5. title\n",
      "   6. channel\n",
      "   7. duration\n",
      "   8. upload_date\n",
      "   9. url\n",
      "  10. audio_path\n",
      "  11. thumbnail_path\n",
      "  12. transcript_path\n",
      "  13. transcript_text\n",
      "  14. transcript_length\n",
      "  15. language\n",
      "  16. label\n",
      "  17. status\n",
      "  18. transcribed_at\n",
      "  19. keyword_tier\n",
      "  20. channel_type\n",
      "  21. cleaned_text\n",
      "  22. normalized_text\n",
      "  23. token_count\n",
      "  24. quality_status\n",
      "  25. repetition_flag\n",
      "\n",
      "Contoh data (5 baris pertama):\n",
      "  sample_id                                              title     channel  \\\n",
      "0  YT_00002  [FULL] Wapres Gibran Umumkan Kado Istimewa dar...    KOMPASTV   \n",
      "1  YT_00003  Live Event Rekam Jejak Prabowo Menjadi Preside...   METRO TV    \n",
      "2  YT_00004  Ulas Utas, Setahun Presiden Prabowo: 'Koruptor...  tvOneNews    \n",
      "3  YT_00005  Reshuffle Kabinet Merah Putih Prabowo-Gibran |...  tvOneNews    \n",
      "4  YT_00006  Presiden Prabowo Subianto \"Cuci\" Kabinet Merah...   SINDOnews   \n",
      "\n",
      "     label  \n",
      "0  unknown  \n",
      "1  unknown  \n",
      "2  unknown  \n",
      "3  unknown  \n",
      "4  unknown  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEMUAT DATA YOUTUBE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Path file JSON (sesuaikan dengan lokasi Anda)\n",
    "json_path = r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\data\\normalization\\metadata_yt.json'\n",
    "\n",
    "print(f\"\\nMembaca file:\")\n",
    "print(f\"  {json_path}\")\n",
    "\n",
    "# Baca file JSON\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data_yt = json.load(f)\n",
    "\n",
    "print(f\"\\nTotal data YouTube: {len(data_yt):,} video\")\n",
    "\n",
    "# Konversi ke DataFrame\n",
    "df_yt = pd.DataFrame(data_yt)\n",
    "\n",
    "print(f\"\\nInfo dataset:\")\n",
    "print(f\"  Total records: {len(df_yt):,}\")\n",
    "print(f\"  Total kolom: {len(df_yt.columns)}\")\n",
    "\n",
    "print(f\"\\nKolom yang tersedia:\")\n",
    "for i, col in enumerate(df_yt.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nContoh data (5 baris pertama):\")\n",
    "print(df_yt[['sample_id', 'title', 'channel', 'label']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a99893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FILTERING DATA BERKUALITAS\n",
      "================================================================================\n",
      "\n",
      "Data awal: 992 video\n",
      "\n",
      "Distribusi Quality Status:\n",
      "quality_status\n",
      "GOOD    992\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Statistik Token Count:\n",
      "count     992.000000\n",
      "mean      476.735887\n",
      "std       287.127861\n",
      "min        10.000000\n",
      "25%       267.000000\n",
      "50%       385.500000\n",
      "75%       631.000000\n",
      "max      1739.000000\n",
      "Name: token_count, dtype: float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KRITERIA FILTERING:\n",
      "--------------------------------------------------------------------------------\n",
      "1. Title tidak kosong\n",
      "2. Normalized text tersedia\n",
      "3. Token count minimal 3\n",
      "4. Quality status = GOOD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "HASIL FILTERING:\n",
      "--------------------------------------------------------------------------------\n",
      "Data awal: 992 video\n",
      "Data valid: 992 video\n",
      "Data difilter: 0 video\n",
      "Persentase lolos: 100.0%\n",
      "\n",
      "Statistik Data Valid:\n",
      "  Rata-rata token: 476.7\n",
      "  Median token: 385.5\n",
      "  Min token: 10\n",
      "  Max token: 1739\n",
      "\n",
      "Top 10 Channel:\n",
      "  METRO TV : 100 video\n",
      "  KOMPASTV: 88 video\n",
      "  tvOneNews : 84 video\n",
      "  Kompas.com: 63 video\n",
      "  Tribunnews: 57 video\n",
      "  Official iNews: 57 video\n",
      "  CNBC Indonesia: 25 video\n",
      "  CNN Indonesia: 23 video\n",
      "  BeritaSatu: 17 video\n",
      "  Tribun MedanTV: 15 video\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FILTERING DATA BERKUALITAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nData awal: {len(df_yt):,} video\")\n",
    "\n",
    "# Tampilkan distribusi quality status\n",
    "print(f\"\\nDistribusi Quality Status:\")\n",
    "print(df_yt['quality_status'].value_counts())\n",
    "\n",
    "# Tampilkan statistik token count\n",
    "print(f\"\\nStatistik Token Count:\")\n",
    "print(df_yt['token_count'].describe())\n",
    "\n",
    "# Kriteria filtering\n",
    "print(f\"\\n\" + \"-\"*80)\n",
    "print(\"KRITERIA FILTERING:\")\n",
    "print(\"-\"*80)\n",
    "print(\"1. Title tidak kosong\")\n",
    "print(\"2. Normalized text tersedia\")\n",
    "print(\"3. Token count minimal 3\")\n",
    "print(\"4. Quality status = GOOD\")\n",
    "\n",
    "# Apply filter\n",
    "df_valid = df_yt[\n",
    "    (df_yt['title'].notna()) &\n",
    "    (df_yt['normalized_text'].notna()) &\n",
    "    (df_yt['token_count'] >= 3) &\n",
    "    (df_yt['quality_status'] == 'GOOD')\n",
    "].copy()\n",
    "\n",
    "# Hasil filtering\n",
    "print(f\"\\n\" + \"-\"*80)\n",
    "print(\"HASIL FILTERING:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Data awal: {len(df_yt):,} video\")\n",
    "print(f\"Data valid: {len(df_valid):,} video\")\n",
    "print(f\"Data difilter: {len(df_yt) - len(df_valid):,} video\")\n",
    "print(f\"Persentase lolos: {len(df_valid)/len(df_yt)*100:.1f}%\")\n",
    "\n",
    "# Statistik data valid\n",
    "print(f\"\\nStatistik Data Valid:\")\n",
    "print(f\"  Rata-rata token: {df_valid['token_count'].mean():.1f}\")\n",
    "print(f\"  Median token: {df_valid['token_count'].median():.1f}\")\n",
    "print(f\"  Min token: {df_valid['token_count'].min()}\")\n",
    "print(f\"  Max token: {df_valid['token_count'].max()}\")\n",
    "\n",
    "# Top 10 channel\n",
    "print(f\"\\nTop 10 Channel:\")\n",
    "top_channels = df_valid['channel'].value_counts().head(10)\n",
    "for channel, count in top_channels.items():\n",
    "    print(f\"  {channel}: {count} video\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ed777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DEFINISI FUNGSI PREDIKSI\n",
      "================================================================================\n",
      "\n",
      "Fungsi prediksi_batch berhasil didefinisikan\n",
      "\n",
      "Spesifikasi fungsi:\n",
      "  Input: List of titles\n",
      "  Output: (predictions, confidences, probabilities)\n",
      "  Label mapping: 0 = Hoax, 1 = Valid\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEFINISI FUNGSI PREDIKSI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def prediksi_batch(titles, batch_size=8, max_length=32):\n",
    "    \"\"\"\n",
    "    Fungsi untuk memprediksi label batch titles menggunakan IndoBERT\n",
    "    \n",
    "    Parameter:\n",
    "        titles: List of title strings\n",
    "        batch_size: Ukuran batch untuk inference (default 8)\n",
    "        max_length: Panjang maksimal token (default 32)\n",
    "    \n",
    "    Return:\n",
    "        predictions: Array prediksi (0=hoax, 1=valid)\n",
    "        confidences: Array confidence scores\n",
    "        probabilities: Array probabilitas [prob_hoax, prob_valid]\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    print(f\"\\nParameter prediksi:\")\n",
    "    print(f\"  Total data: {len(titles):,}\")\n",
    "    print(f\"  Batch size: {batch_size}\")\n",
    "    print(f\"  Max length: {max_length}\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    \n",
    "    print(f\"\\nMemulai prediksi...\")\n",
    "    \n",
    "    # Proses batch dengan progress bar\n",
    "    for i in tqdm(range(0, len(titles), batch_size), desc=\"Progress\"):\n",
    "        batch_titles = titles[i:i+batch_size]\n",
    "        \n",
    "        # Tokenisasi\n",
    "        inputs = tokenizer(\n",
    "            batch_titles,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        \n",
    "        # Prediksi tanpa gradient\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        # Ambil confidence dan prediksi\n",
    "        confidences, predictions = torch.max(probs, dim=1)\n",
    "        \n",
    "        # Simpan hasil\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_confidences.extend(confidences.cpu().numpy())\n",
    "        all_probabilities.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return (\n",
    "        np.array(all_predictions),\n",
    "        np.array(all_confidences),\n",
    "        np.array(all_probabilities)\n",
    "    )\n",
    "\n",
    "print(\"\\nFungsi prediksi_batch berhasil didefinisikan\")\n",
    "print(\"\\nSpesifikasi fungsi:\")\n",
    "print(\"  Input: List of titles\")\n",
    "print(\"  Output: (predictions, confidences, probabilities)\")\n",
    "print(\"  Label mapping: 0 = Hoax, 1 = Valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38e9bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROSES PSEUDO-LABELING\n",
      "================================================================================\n",
      "\n",
      "Total title yang akan diprediksi: 992\n",
      "Estimasi waktu: sekitar 62 detik\n",
      "\n",
      "Parameter prediksi:\n",
      "  Total data: 992\n",
      "  Batch size: 8\n",
      "  Max length: 32\n",
      "  Device: cuda\n",
      "\n",
      "Memulai prediksi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 124/124 [00:04<00:00, 24.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "HASIL PSEUDO-LABELING\n",
      "================================================================================\n",
      "\n",
      "Pseudo-labeling selesai\n",
      "Total data yang dilabeli: 992\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DISTRIBUSI PREDIKSI:\n",
      "--------------------------------------------------------------------------------\n",
      "predicted_label_str\n",
      "valid    971\n",
      "hoax      21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ratio Valid:Hoax = 46.2:1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "STATISTIK CONFIDENCE:\n",
      "--------------------------------------------------------------------------------\n",
      "  Rata-rata: 0.9267\n",
      "  Median: 0.9594\n",
      "  Min: 0.5027\n",
      "  Max: 0.9949\n",
      "  Std Dev: 0.0884\n",
      "\n",
      "Quartiles:\n",
      "25%    0.920848\n",
      "50%    0.959390\n",
      "75%    0.975943\n",
      "Name: confidence, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROSES PSEUDO-LABELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Gunakan normalized_text untuk prediksi\n",
    "titles_to_label = df_valid['normalized_text'].tolist()\n",
    "\n",
    "print(f\"\\nTotal title yang akan diprediksi: {len(titles_to_label):,}\")\n",
    "print(f\"Estimasi waktu: sekitar {len(titles_to_label)/8*0.5:.0f} detik\")\n",
    "\n",
    "# Jalankan prediksi\n",
    "predictions, confidences, probabilities = prediksi_batch(\n",
    "    titles_to_label,\n",
    "    batch_size=8,\n",
    "    max_length=32\n",
    ")\n",
    "\n",
    "# Tambahkan hasil ke dataframe\n",
    "df_valid['predicted_label'] = predictions\n",
    "df_valid['confidence'] = confidences\n",
    "df_valid['prob_hoax'] = probabilities[:, 0]\n",
    "df_valid['prob_valid'] = probabilities[:, 1]\n",
    "\n",
    "# Konversi ke string label\n",
    "df_valid['predicted_label_str'] = df_valid['predicted_label'].map({\n",
    "    0: 'hoax',\n",
    "    1: 'valid'\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HASIL PSEUDO-LABELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nPseudo-labeling selesai\")\n",
    "print(f\"Total data yang dilabeli: {len(df_valid):,}\")\n",
    "\n",
    "# Distribusi prediksi\n",
    "print(f\"\\n\" + \"-\"*80)\n",
    "print(\"DISTRIBUSI PREDIKSI:\")\n",
    "print(\"-\"*80)\n",
    "dist = df_valid['predicted_label_str'].value_counts()\n",
    "print(dist)\n",
    "\n",
    "if 'hoax' in dist.index and 'valid' in dist.index:\n",
    "    ratio = dist['valid'] / dist['hoax']\n",
    "    print(f\"\\nRatio Valid:Hoax = {ratio:.1f}:1\")\n",
    "\n",
    "# Statistik confidence\n",
    "print(f\"\\n\" + \"-\"*80)\n",
    "print(\"STATISTIK CONFIDENCE:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Rata-rata: {df_valid['confidence'].mean():.4f}\")\n",
    "print(f\"  Median: {df_valid['confidence'].median():.4f}\")\n",
    "print(f\"  Min: {df_valid['confidence'].min():.4f}\")\n",
    "print(f\"  Max: {df_valid['confidence'].max():.4f}\")\n",
    "print(f\"  Std Dev: {df_valid['confidence'].std():.4f}\")\n",
    "\n",
    "print(f\"\\nQuartiles:\")\n",
    "print(df_valid['confidence'].describe()[['25%', '50%', '75%']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962bf91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALISIS DETAIL HASIL PREDIKSI\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "BAGIAN 1: VIDEO YANG DIPREDIKSI HOAX\n",
      "================================================================================\n",
      "\n",
      "Total hoax terdeteksi: 21\n",
      "\n",
      "Rincian 10 hoax teratas:\n",
      "\n",
      "1. [YT_00081]\n",
      "   Title: Publik Geram, Hukum Tumpul di Kasus Silfester? - [Selamat Pagi Indonesia]...\n",
      "   Channel: METRO TV \n",
      "   Confidence: 0.9056 (90.56%)\n",
      "   Prob [Hoax|Valid]: [0.9056|0.0944]\n",
      "\n",
      "2. [YT_00867]\n",
      "   Title: Wakil Presiden Gibran Rakabuming Raka Digugat Rp125 Triliun, Jabatan Wapres Diminta Dibatalkan...\n",
      "   Channel: Banjarmasin Post News Video\n",
      "   Confidence: 0.8510 (85.10%)\n",
      "   Prob [Hoax|Valid]: [0.8510|0.1490]\n",
      "\n",
      "3. [YT_00904]\n",
      "   Title: Peran dan Ideologi Partai Politik di Indonesia | UAS Sistem Politik Indonesia...\n",
      "   Channel: scientialoquendi\n",
      "   Confidence: 0.7721 (77.21%)\n",
      "   Prob [Hoax|Valid]: [0.7721|0.2279]\n",
      "\n",
      "4. [YT_01161]\n",
      "   Title: [BREAKING NEWS] Sederet Nama yang Dilantik Menjadi Komisi Percepatan Reformasi Polri | tvOne...\n",
      "   Channel: tvOneNews \n",
      "   Confidence: 0.7557 (75.57%)\n",
      "   Prob [Hoax|Valid]: [0.7557|0.2443]\n",
      "\n",
      "5. [YT_00039]\n",
      "   Title: Apakah Benar Jokowi Jadi Sekjen PBB 2026? | OneNews Update...\n",
      "   Channel: tvOneNews \n",
      "   Confidence: 0.7114 (71.14%)\n",
      "   Prob [Hoax|Valid]: [0.7114|0.2886]\n",
      "\n",
      "6. [YT_00046]\n",
      "   Title: Apakah Benar Jokowi Jadi Sekjen PBB 2026? | OneNews Update...\n",
      "   Channel: tvOneNews \n",
      "   Confidence: 0.7114 (71.14%)\n",
      "   Prob [Hoax|Valid]: [0.7114|0.2886]\n",
      "\n",
      "7. [YT_00132]\n",
      "   Title: Jaga Stabilitas Negara, Pemerintah Fokus Sistem Pertahanan Udara - [Metro Pagi Primetime]...\n",
      "   Channel: METRO TV \n",
      "   Confidence: 0.7104 (71.04%)\n",
      "   Prob [Hoax|Valid]: [0.7104|0.2896]\n",
      "\n",
      "8. [YT_00665]\n",
      "   Title: Jokowi:  Upaya Mencari Dukugan, Isu Keluarga  dan Politik Indonesia...\n",
      "   Channel: Veritas Aktual\n",
      "   Confidence: 0.7082 (70.82%)\n",
      "   Prob [Hoax|Valid]: [0.7082|0.2918]\n",
      "\n",
      "9. [YT_00011]\n",
      "   Title: Mengapa Presiden Prabowo Selalu Pilih Kader Gerindra dalam Reshuffle Kabinet?...\n",
      "   Channel: Kompas.com\n",
      "   Confidence: 0.6828 (68.28%)\n",
      "   Prob [Hoax|Valid]: [0.6828|0.3172]\n",
      "\n",
      "10. [YT_00842]\n",
      "   Title: Kinerja Pemerintahan Prabowo - Gibran 1 Tahun Pertama | Primetime News...\n",
      "   Channel: METRO TV \n",
      "   Confidence: 0.6181 (61.81%)\n",
      "   Prob [Hoax|Valid]: [0.6181|0.3819]\n",
      "\n",
      "================================================================================\n",
      "BAGIAN 2: VALID DENGAN CONFIDENCE RENDAH (Borderline Cases)\n",
      "================================================================================\n",
      "\n",
      "Distribusi berdasarkan threshold confidence:\n",
      "  Confidence < 0.70: 44 samples\n",
      "  Confidence < 0.75: 56 samples\n",
      "  Confidence < 0.80: 78 samples\n",
      "  Confidence < 0.90: 194 samples\n",
      "\n",
      "15 Valid dengan Confidence Terendah (Potensi untuk Reclassify):\n",
      "\n",
      "1. [YT_00593] Conf: 0.5100\n",
      "   Title: [HEADLINE NEWS 09/09] Ustaz Khalid Basalamah Diperiksa KPK Soal Dugaan Korupsi K...\n",
      "   Channel: METRO TV \n",
      "   Prob [Hoax|Valid]: [0.4900|0.5100]\n",
      "\n",
      "2. [YT_00416] Conf: 0.5121\n",
      "   Title: Keamanan Suatu Negara: Fondasi Kedaulatan dan Pertahanan Nasional Indonesia...\n",
      "   Channel:  786,FactPulse\n",
      "   Prob [Hoax|Valid]: [0.4879|0.5121]\n",
      "\n",
      "3. [YT_01018] Conf: 0.5241\n",
      "   Title: Informasi Permohonan Izin Besuk Tahanan Pada Pengadilan Negeri Negara menggunaka...\n",
      "   Channel: Pengadilan Negeri Negara\n",
      "   Prob [Hoax|Valid]: [0.4759|0.5241]\n",
      "\n",
      "4. [YT_00609] Conf: 0.5437\n",
      "   Title: BIKIN TERANG DUGAAN PATGULIPAT KERETA CEPAT, SIAPA YANG SALAH?...\n",
      "   Channel: Official iNews\n",
      "   Prob [Hoax|Valid]: [0.4563|0.5437]\n",
      "\n",
      "5. [YT_00363] Conf: 0.5490\n",
      "   Title: Prabowo's 'Red and White' cabinet is Indonesia's largest since 1960s...\n",
      "   Channel: CNA\n",
      "   Prob [Hoax|Valid]: [0.4510|0.5490]\n",
      "\n",
      "6. [YT_01166] Conf: 0.5605\n",
      "   Title: (Berita Video) 8 September 2025 : Sidang PUU POLRI, Mendengarkan Keterangan  DPR...\n",
      "   Channel: Mahkamah Konstitusi RI\n",
      "   Prob [Hoax|Valid]: [0.4395|0.5605]\n",
      "\n",
      "7. [YT_00510] Conf: 0.5669\n",
      "   Title: Ulas Utas: Presiden Prabowo Tak Mempan Disogok Koruptor | tvOne...\n",
      "   Channel: tvOneNews \n",
      "   Prob [Hoax|Valid]: [0.4331|0.5669]\n",
      "\n",
      "8. [YT_00221] Conf: 0.5793\n",
      "   Title: [HEADLINE NEWS, 31/10] Pasca-Jaksa Periksa Wakil Wali Kota Bandung...\n",
      "   Channel: METRO TV \n",
      "   Prob [Hoax|Valid]: [0.4207|0.5793]\n",
      "\n",
      "9. [YT_00527] Conf: 0.5925\n",
      "   Title: Puas Kinerja Kabinet Merah Putih, Prabowo: Saya Terkejut, Mereka Bekerja Sangat ...\n",
      "   Channel: Kompas.com\n",
      "   Prob [Hoax|Valid]: [0.4075|0.5925]\n",
      "\n",
      "10. [YT_01500] Conf: 0.5937\n",
      "   Title: Presiden Iran Ajak Prabowo Bertemu, Apresiasi Diplomasi Indonesia...\n",
      "   Channel: KompasTV Jember\n",
      "   Prob [Hoax|Valid]: [0.4063|0.5937]\n",
      "\n",
      "11. [YT_00033] Conf: 0.5985\n",
      "   Title: Wakil Presiden Gibran Rakabuming Raka Resmikan Kantor Pusat SENKOM Mitra Polri |...\n",
      "   Channel: tvOneNews \n",
      "   Prob [Hoax|Valid]: [0.4015|0.5985]\n",
      "\n",
      "12. [YT_01522] Conf: 0.6026\n",
      "   Title: Detik-detik Prabowo Tinggalkan Indonesia Hadiri KTT ASEAN di Malaysia, Sempat Be...\n",
      "   Channel: Tribunnews\n",
      "   Prob [Hoax|Valid]: [0.3974|0.6026]\n",
      "\n",
      "13. [YT_01337] Conf: 0.6057\n",
      "   Title: Kantor Menkeu Purbaya Digeruduk Belasan Gubernur Buntut Pemotongan Anggaran ke P...\n",
      "   Channel: Tribunnews\n",
      "   Prob [Hoax|Valid]: [0.3943|0.6057]\n",
      "\n",
      "14. [YT_01146] Conf: 0.6283\n",
      "   Title: PCO Tanggapi Desakan PBB soal Pelanggaran HAM pada Aksi Demo | Kabar Utama tvOne...\n",
      "   Channel: tvOneNews \n",
      "   Prob [Hoax|Valid]: [0.3717|0.6283]\n",
      "\n",
      "15. [YT_00638] Conf: 0.6288\n",
      "   Title: LAGU KRITIK PEMERINTAH || TUNJANGAN JOGETAN - NOIRNA RAP HIJAB (Official Music V...\n",
      "   Channel: Noirna\n",
      "   Prob [Hoax|Valid]: [0.3712|0.6288]\n",
      "\n",
      "================================================================================\n",
      "BAGIAN 3: DISTRIBUSI CONFIDENCE PER RANGE\n",
      "================================================================================\n",
      "\n",
      "Distribusi per Label dan Confidence Range:\n",
      "conf_range           0.50-0.60  0.60-0.70  0.70-0.80  0.80-0.90  0.90-0.95  \\\n",
      "predicted_label_str                                                          \n",
      "hoax                        11          2          6          1          1   \n",
      "valid                       11         20         28        115        207   \n",
      "\n",
      "conf_range           0.95-1.00  \n",
      "predicted_label_str             \n",
      "hoax                         0  \n",
      "valid                      590  \n",
      "\n",
      "================================================================================\n",
      "BAGIAN 4: ANALISIS PER CHANNEL\n",
      "================================================================================\n",
      "\n",
      "Top 10 Channel dengan Hoax Terbanyak:\n",
      "                             avg_conf  std_conf  total_video  hoax_count\n",
      "channel                                                                 \n",
      "METRO TV                       0.9363    0.0844          100           3\n",
      "tvOneNews                      0.9076    0.1014           84           3\n",
      "Kompas.com                     0.9155    0.0951           63           2\n",
      "Veritas Aktual                 0.8049    0.1831            6           2\n",
      "Media Indonesia                0.5113       NaN            1           1\n",
      "SINDOnews                      0.8619    0.2073            4           1\n",
      "Harian Surya                   0.8725    0.1816            6           1\n",
      "PBS NewsHour                   0.5799       NaN            1           1\n",
      "Banjarmasin Post News Video    0.9392    0.0764            3           1\n",
      "media ngasal                   0.5370       NaN            1           1\n",
      "\n",
      "Top 10 Channel dengan Confidence Terendah:\n",
      "                                                    confidence\n",
      "channel                                                       \n",
      "Media Indonesia                                       0.511295\n",
      "media ngasal                                          0.537028\n",
      "Wakil Presiden Republik Indonesia                     0.557154\n",
      "Mahkamah Konstitusi RI                                0.560451\n",
      "PBS NewsHour                                          0.579863\n",
      "Daniel K. Inouye Asia-Pacific Center for Securi...    0.592203\n",
      "WION                                                  0.647195\n",
      "BWS Sumatera VII Bengkulu                             0.661406\n",
      "Forbes Breaking News                                  0.661526\n",
      "CNA                                                   0.680631\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALISIS DETAIL HASIL PREDIKSI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# BAGIAN 1: Analisis hoax yang terdeteksi\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BAGIAN 1: VIDEO YANG DIPREDIKSI HOAX\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_hoax_detected = df_valid[df_valid['predicted_label_str'] == 'hoax'].copy()\n",
    "df_hoax_detected = df_hoax_detected.sort_values('confidence', ascending=False)\n",
    "\n",
    "print(f\"\\nTotal hoax terdeteksi: {len(df_hoax_detected)}\")\n",
    "print(f\"\\nRincian {min(10, len(df_hoax_detected))} hoax teratas:\")\n",
    "\n",
    "for idx, (i, row) in enumerate(df_hoax_detected.head(10).iterrows(), 1):\n",
    "    print(f\"\\n{idx}. [{row['sample_id']}]\")\n",
    "    print(f\"   Title: {row['title'][:100]}...\")\n",
    "    print(f\"   Channel: {row['channel']}\")\n",
    "    print(f\"   Confidence: {row['confidence']:.4f} ({row['confidence']*100:.2f}%)\")\n",
    "    print(f\"   Prob [Hoax|Valid]: [{row['prob_hoax']:.4f}|{row['prob_valid']:.4f}]\")\n",
    "\n",
    "# BAGIAN 2: Valid dengan confidence rendah (borderline)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BAGIAN 2: VALID DENGAN CONFIDENCE RENDAH (Borderline Cases)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Hitung berapa banyak di tiap range\n",
    "n_below_70 = (df_valid['confidence'] < 0.70).sum()\n",
    "n_below_75 = (df_valid['confidence'] < 0.75).sum()\n",
    "n_below_80 = (df_valid['confidence'] < 0.80).sum()\n",
    "n_below_90 = (df_valid['confidence'] < 0.90).sum()\n",
    "\n",
    "print(f\"\\nDistribusi berdasarkan threshold confidence:\")\n",
    "print(f\"  Confidence < 0.70: {n_below_70:,} samples\")\n",
    "print(f\"  Confidence < 0.75: {n_below_75:,} samples\")\n",
    "print(f\"  Confidence < 0.80: {n_below_80:,} samples\")\n",
    "print(f\"  Confidence < 0.90: {n_below_90:,} samples\")\n",
    "\n",
    "# Tampilkan top 15 borderline\n",
    "df_borderline = df_valid[\n",
    "    df_valid['predicted_label_str'] == 'valid'\n",
    "].nsmallest(15, 'confidence')\n",
    "\n",
    "print(f\"\\n15 Valid dengan Confidence Terendah (Potensi untuk Reclassify):\")\n",
    "for idx, (i, row) in enumerate(df_borderline.iterrows(), 1):\n",
    "    print(f\"\\n{idx}. [{row['sample_id']}] Conf: {row['confidence']:.4f}\")\n",
    "    print(f\"   Title: {row['title'][:80]}...\")\n",
    "    print(f\"   Channel: {row['channel']}\")\n",
    "    print(f\"   Prob [Hoax|Valid]: [{row['prob_hoax']:.4f}|{row['prob_valid']:.4f}]\")\n",
    "\n",
    "# BAGIAN 3: Distribusi confidence per range\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BAGIAN 3: DISTRIBUSI CONFIDENCE PER RANGE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "bins = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1.0]\n",
    "labels = ['0.50-0.60', '0.60-0.70', '0.70-0.80', '0.80-0.90', '0.90-0.95', '0.95-1.00']\n",
    "\n",
    "df_valid['conf_range'] = pd.cut(df_valid['confidence'], bins=bins, labels=labels)\n",
    "\n",
    "print(\"\\nDistribusi per Label dan Confidence Range:\")\n",
    "dist_table = df_valid.groupby(['predicted_label_str', 'conf_range']).size().unstack(fill_value=0)\n",
    "print(dist_table)\n",
    "\n",
    "# BAGIAN 4: Analisis per channel\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BAGIAN 4: ANALISIS PER CHANNEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "channel_stats = df_valid.groupby('channel').agg({\n",
    "    'confidence': ['mean', 'std', 'count'],\n",
    "    'predicted_label_str': lambda x: (x == 'hoax').sum()\n",
    "}).round(4)\n",
    "\n",
    "channel_stats.columns = ['avg_conf', 'std_conf', 'total_video', 'hoax_count']\n",
    "channel_stats = channel_stats.sort_values('hoax_count', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Channel dengan Hoax Terbanyak:\")\n",
    "print(channel_stats.head(10))\n",
    "\n",
    "print(\"\\nTop 10 Channel dengan Confidence Terendah:\")\n",
    "channel_low_conf = df_valid.groupby('channel').agg({\n",
    "    'confidence': 'mean'\n",
    "}).sort_values('confidence', ascending=True)\n",
    "print(channel_low_conf.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c73f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STRATEGI BALANCING DENGAN RECLASSIFICATION\n",
      "================================================================================\n",
      "\n",
      "KONFIGURASI:\n",
      "  Hoax threshold (reclassify borderline): < 0.7\n",
      "  Valid threshold (high-confidence): >= 0.9\n",
      "  Target ratio Valid:Hoax: 3.0:1\n",
      "  Max hoax samples: 80\n",
      "  Total budget: 300\n",
      "\n",
      "================================================================================\n",
      "TAHAP 1: HOAX YANG SUDAH TERDETEKSI\n",
      "================================================================================\n",
      "\n",
      "Hoax terdeteksi langsung: 21\n",
      "Confidence range: 0.5027 - 0.9056\n",
      "\n",
      "================================================================================\n",
      "TAHAP 2: RECLASSIFY BORDERLINE VALID\n",
      "================================================================================\n",
      "\n",
      "Total borderline valid (conf < 0.7): 31\n",
      "Borderline yang di-reclassify: 31\n",
      "Confidence range reclassified: 0.5100 - 0.6999\n",
      "\n",
      "================================================================================\n",
      "TAHAP 3: GABUNGKAN HOAX\n",
      "================================================================================\n",
      "\n",
      "Total hoax final:\n",
      "  Predicted hoax: 21\n",
      "  Reclassified: 31\n",
      "  Total: 52\n",
      "\n",
      "================================================================================\n",
      "TAHAP 4: SELEKSI VALID HIGH-CONFIDENCE\n",
      "================================================================================\n",
      "\n",
      "Valid tersedia (conf >= 0.9): 797\n",
      "Valid dipilih: 156\n",
      "Confidence range: 0.9813 - 0.9949\n",
      "\n",
      "================================================================================\n",
      "TAHAP 5: HASIL FINAL BALANCED DATASET\n",
      "================================================================================\n",
      "\n",
      "Distribusi Final:\n",
      "predicted_label_str\n",
      "valid    156\n",
      "hoax      52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ratio Final Valid:Hoax: 3.00:1\n",
      "Total Pseudo-Labels: 208\n",
      "\n",
      "================================================================================\n",
      "STATISTIK CONFIDENCE PER CLASS\n",
      "================================================================================\n",
      "\n",
      "HOAX:\n",
      "  Count: 52\n",
      "  Mean confidence: 0.6278\n",
      "  Median confidence: 0.6285\n",
      "  Min confidence: 0.5027\n",
      "  Max confidence: 0.9056\n",
      "  Std Dev: 0.0859\n",
      "\n",
      "VALID:\n",
      "  Count: 156\n",
      "  Mean confidence: 0.9860\n",
      "  Median confidence: 0.9859\n",
      "  Min confidence: 0.9813\n",
      "  Max confidence: 0.9949\n",
      "  Std Dev: 0.0030\n",
      "\n",
      "================================================================================\n",
      "BREAKDOWN PER SOURCE TYPE\n",
      "================================================================================\n",
      "source_type          high_confidence  predicted_hoax  reclassified\n",
      "predicted_label_str                                               \n",
      "hoax                               0              21            31\n",
      "valid                            156               0             0\n",
      "\n",
      "Total borderline cases yang di-reclassify: 31 (14.9%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGI BALANCING DENGAN RECLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# KONFIGURASI BALANCING\n",
    "HOAX_THRESHOLD = 0.70        # Borderline valid dengan conf < 0.70 → reclassify jadi hoax\n",
    "VALID_THRESHOLD = 0.90       # Valid dengan conf >= 0.90 untuk high-quality samples\n",
    "TARGET_RATIO = 3.0           # Target ratio Valid:Hoax\n",
    "MAX_HOAX_SAMPLES = 80        # Maksimal hoax samples yang diinginkan\n",
    "TOTAL_BUDGET = 300           # Total maksimal pseudo-labels\n",
    "\n",
    "print(\"\\nKONFIGURASI:\")\n",
    "print(f\"  Hoax threshold (reclassify borderline): < {HOAX_THRESHOLD}\")\n",
    "print(f\"  Valid threshold (high-confidence): >= {VALID_THRESHOLD}\")\n",
    "print(f\"  Target ratio Valid:Hoax: {TARGET_RATIO}:1\")\n",
    "print(f\"  Max hoax samples: {MAX_HOAX_SAMPLES}\")\n",
    "print(f\"  Total budget: {TOTAL_BUDGET}\")\n",
    "\n",
    "# TAHAP 1: Ambil hoax yang sudah terdeteksi\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TAHAP 1: HOAX YANG SUDAH TERDETEKSI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_hoax_original = df_valid[df_valid['predicted_label_str'] == 'hoax'].copy()\n",
    "df_hoax_original['source_type'] = 'predicted_hoax'\n",
    "\n",
    "print(f\"\\nHoax terdeteksi langsung: {len(df_hoax_original)}\")\n",
    "print(f\"Confidence range: {df_hoax_original['confidence'].min():.4f} - {df_hoax_original['confidence'].max():.4f}\")\n",
    "\n",
    "# TAHAP 2: Reclassify borderline valid sebagai hoax\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TAHAP 2: RECLASSIFY BORDERLINE VALID\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_borderline = df_valid[\n",
    "    (df_valid['predicted_label_str'] == 'valid') &\n",
    "    (df_valid['confidence'] < HOAX_THRESHOLD)\n",
    "].copy()\n",
    "\n",
    "# Sort by confidence ascending (yang paling uncertain dulu)\n",
    "df_borderline = df_borderline.sort_values('confidence', ascending=True)\n",
    "\n",
    "print(f\"\\nTotal borderline valid (conf < {HOAX_THRESHOLD}): {len(df_borderline)}\")\n",
    "\n",
    "# Limit agar tidak melebihi MAX_HOAX_SAMPLES\n",
    "n_borderline_needed = min(\n",
    "    MAX_HOAX_SAMPLES - len(df_hoax_original),\n",
    "    len(df_borderline)\n",
    ")\n",
    "\n",
    "df_borderline_selected = df_borderline.head(n_borderline_needed)\n",
    "df_borderline_selected['source_type'] = 'reclassified'\n",
    "df_borderline_selected['predicted_label_str'] = 'hoax'\n",
    "\n",
    "print(f\"Borderline yang di-reclassify: {len(df_borderline_selected)}\")\n",
    "print(f\"Confidence range reclassified: {df_borderline_selected['confidence'].min():.4f} - {df_borderline_selected['confidence'].max():.4f}\")\n",
    "\n",
    "# TAHAP 3: Gabungkan semua hoax\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TAHAP 3: GABUNGKAN HOAX\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_hoax_final = pd.concat([df_hoax_original, df_borderline_selected])\n",
    "\n",
    "print(f\"\\nTotal hoax final:\")\n",
    "print(f\"  Predicted hoax: {len(df_hoax_original)}\")\n",
    "print(f\"  Reclassified: {len(df_borderline_selected)}\")\n",
    "print(f\"  Total: {len(df_hoax_final)}\")\n",
    "\n",
    "# TAHAP 4: Pilih valid dengan high-confidence\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TAHAP 4: SELEKSI VALID HIGH-CONFIDENCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_valid_highconf = df_valid[\n",
    "    (df_valid['predicted_label_str'] == 'valid') &\n",
    "    (df_valid['confidence'] >= VALID_THRESHOLD)\n",
    "].copy()\n",
    "\n",
    "# Sort by confidence descending\n",
    "df_valid_highconf = df_valid_highconf.sort_values('confidence', ascending=False)\n",
    "\n",
    "# Hitung berapa valid yang dibutuhkan untuk target ratio\n",
    "n_valid_needed = int(len(df_hoax_final) * TARGET_RATIO)\n",
    "n_valid_needed = min(n_valid_needed, len(df_valid_highconf))\n",
    "\n",
    "# Adjust jika melebihi budget\n",
    "if len(df_hoax_final) + n_valid_needed > TOTAL_BUDGET:\n",
    "    n_valid_needed = TOTAL_BUDGET - len(df_hoax_final)\n",
    "\n",
    "df_valid_selected = df_valid_highconf.head(n_valid_needed)\n",
    "df_valid_selected['source_type'] = 'high_confidence'\n",
    "\n",
    "print(f\"\\nValid tersedia (conf >= {VALID_THRESHOLD}): {len(df_valid_highconf)}\")\n",
    "print(f\"Valid dipilih: {n_valid_needed}\")\n",
    "print(f\"Confidence range: {df_valid_selected['confidence'].min():.4f} - {df_valid_selected['confidence'].max():.4f}\")\n",
    "\n",
    "# TAHAP 5: Gabungkan hasil final\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TAHAP 5: HASIL FINAL BALANCED DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_balanced = pd.concat([df_hoax_final, df_valid_selected])\n",
    "\n",
    "# Statistik final\n",
    "dist_final = df_balanced['predicted_label_str'].value_counts()\n",
    "print(f\"\\nDistribusi Final:\")\n",
    "print(dist_final)\n",
    "\n",
    "if 'hoax' in dist_final.index and 'valid' in dist_final.index:\n",
    "    final_ratio = dist_final['valid'] / dist_final['hoax']\n",
    "    print(f\"\\nRatio Final Valid:Hoax: {final_ratio:.2f}:1\")\n",
    "\n",
    "print(f\"Total Pseudo-Labels: {len(df_balanced)}\")\n",
    "\n",
    "# Statistik per class\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTIK CONFIDENCE PER CLASS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for label in ['hoax', 'valid']:\n",
    "    subset = df_balanced[df_balanced['predicted_label_str'] == label]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{label.upper()}:\")\n",
    "        print(f\"  Count: {len(subset)}\")\n",
    "        print(f\"  Mean confidence: {subset['confidence'].mean():.4f}\")\n",
    "        print(f\"  Median confidence: {subset['confidence'].median():.4f}\")\n",
    "        print(f\"  Min confidence: {subset['confidence'].min():.4f}\")\n",
    "        print(f\"  Max confidence: {subset['confidence'].max():.4f}\")\n",
    "        print(f\"  Std Dev: {subset['confidence'].std():.4f}\")\n",
    "\n",
    "# Info source type\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BREAKDOWN PER SOURCE TYPE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "source_breakdown = df_balanced.groupby(['predicted_label_str', 'source_type']).size().unstack(fill_value=0)\n",
    "print(source_breakdown)\n",
    "\n",
    "n_reclassified = (df_balanced['source_type'] == 'reclassified').sum()\n",
    "pct_reclassified = n_reclassified / len(df_balanced) * 100\n",
    "\n",
    "print(f\"\\nTotal borderline cases yang di-reclassify: {n_reclassified} ({pct_reclassified:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea6b7611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALISIS DISTRIBUSI CONFIDENCE\n",
      "================================================================================\n",
      "\n",
      "Distribusi Confidence per Class:\n",
      "\n",
      "HOAX:\n",
      "  0.50-0.60:  22 ( 42.3%)\n",
      "  0.60-0.70:  22 ( 42.3%)\n",
      "  0.70-0.80:   6 ( 11.5%)\n",
      "  0.80-0.90:   1 (  1.9%)\n",
      "  0.90-0.95:   1 (  1.9%)\n",
      "  0.95-1.00:   0 (  0.0%)\n",
      "\n",
      "VALID:\n",
      "  0.50-0.60:   0 (  0.0%)\n",
      "  0.60-0.70:   0 (  0.0%)\n",
      "  0.70-0.80:   0 (  0.0%)\n",
      "  0.80-0.90:   0 (  0.0%)\n",
      "  0.90-0.95:   0 (  0.0%)\n",
      "  0.95-1.00: 156 (100.0%)\n",
      "\n",
      "================================================================================\n",
      "CROSS-TABLE DISTRIBUSI\n",
      "================================================================================\n",
      "conf_bin             0.50-0.60  0.60-0.70  0.70-0.80  0.80-0.90  0.90-0.95  \\\n",
      "predicted_label_str                                                          \n",
      "hoax                        22         22          6          1          1   \n",
      "valid                        0          0          0          0          0   \n",
      "All                         22         22          6          1          1   \n",
      "\n",
      "conf_bin             0.95-1.00  All  \n",
      "predicted_label_str                  \n",
      "hoax                         0   52  \n",
      "valid                      156  156  \n",
      "All                        156  208  \n",
      "\n",
      "================================================================================\n",
      "BREAKDOWN HOAX PER CONFIDENCE RANGE DAN SOURCE\n",
      "================================================================================\n",
      "\n",
      "0.50-0.60: 22 samples\n",
      "  Predicted hoax: 11\n",
      "  Reclassified: 11\n",
      "\n",
      "0.60-0.70: 22 samples\n",
      "  Predicted hoax: 2\n",
      "  Reclassified: 20\n",
      "\n",
      "0.70-0.80: 6 samples\n",
      "  Predicted hoax: 6\n",
      "  Reclassified: 0\n",
      "\n",
      "0.80-0.90: 1 samples\n",
      "  Predicted hoax: 1\n",
      "  Reclassified: 0\n",
      "\n",
      "0.90-0.95: 1 samples\n",
      "  Predicted hoax: 1\n",
      "  Reclassified: 0\n",
      "\n",
      "================================================================================\n",
      "CHANNEL DISTRIBUTION UNTUK HOAX\n",
      "================================================================================\n",
      "\n",
      "Top 15 Channel dengan Hoax Terbanyak:\n",
      "   1. tvOneNews : 9 hoax\n",
      "   2. METRO TV : 6 hoax\n",
      "   3. Kompas.com: 5 hoax\n",
      "   4. Tribunnews: 4 hoax\n",
      "   5. Official iNews: 2 hoax\n",
      "   6. Veritas Aktual: 2 hoax\n",
      "   7. Ringkas Saja: 1 hoax\n",
      "   8. Forbes Breaking News: 1 hoax\n",
      "   9. CNA: 1 hoax\n",
      "  10. BWS Sumatera VII Bengkulu: 1 hoax\n",
      "  11. Tribun Sumsel: 1 hoax\n",
      "  12. WION: 1 hoax\n",
      "  13. KOMPASTV: 1 hoax\n",
      "  14. Noirna: 1 hoax\n",
      "  15. TV Tempo: 1 hoax\n",
      "\n",
      "================================================================================\n",
      "CHANNEL DISTRIBUTION UNTUK VALID\n",
      "================================================================================\n",
      "\n",
      "Top 10 Channel Valid:\n",
      "   1. METRO TV : 19 valid\n",
      "   2. KOMPASTV: 18 valid\n",
      "   3. tvOneNews : 11 valid\n",
      "   4. Tribunnews: 10 valid\n",
      "   5. Official iNews: 6 valid\n",
      "   6. CNN Indonesia: 5 valid\n",
      "   7. Kompas.com: 5 valid\n",
      "   8. IDX CHANNEL: 4 valid\n",
      "   9. Harian Kompas: 4 valid\n",
      "  10. CNBC Indonesia: 3 valid\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALISIS DISTRIBUSI CONFIDENCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Buat confidence bins\n",
    "bins = [0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 1.0]\n",
    "labels_bins = ['0.50-0.60', '0.60-0.70', '0.70-0.80', '0.80-0.90', '0.90-0.95', '0.95-1.00']\n",
    "\n",
    "df_balanced['conf_bin'] = pd.cut(\n",
    "    df_balanced['confidence'],\n",
    "    bins=bins,\n",
    "    labels=labels_bins\n",
    ")\n",
    "\n",
    "# Distribusi per class\n",
    "print(\"\\nDistribusi Confidence per Class:\")\n",
    "\n",
    "for label in ['hoax', 'valid']:\n",
    "    subset = df_balanced[df_balanced['predicted_label_str'] == label]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{label.upper()}:\")\n",
    "        bin_dist = subset['conf_bin'].value_counts().sort_index()\n",
    "        for bin_name, count in bin_dist.items():\n",
    "            pct = count / len(subset) * 100\n",
    "            print(f\"  {bin_name}: {count:3d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Cross-table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-TABLE DISTRIBUSI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cross_tab = pd.crosstab(\n",
    "    df_balanced['predicted_label_str'],\n",
    "    df_balanced['conf_bin'],\n",
    "    margins=True\n",
    ")\n",
    "print(cross_tab)\n",
    "\n",
    "# Breakdown hoax per source type dan confidence range\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BREAKDOWN HOAX PER CONFIDENCE RANGE DAN SOURCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "hoax_subset = df_balanced[df_balanced['predicted_label_str'] == 'hoax']\n",
    "\n",
    "for bin_name in labels_bins:\n",
    "    bin_data = hoax_subset[hoax_subset['conf_bin'] == bin_name]\n",
    "    if len(bin_data) > 0:\n",
    "        n_predicted = (bin_data['source_type'] == 'predicted_hoax').sum()\n",
    "        n_reclassified = (bin_data['source_type'] == 'reclassified').sum()\n",
    "        \n",
    "        print(f\"\\n{bin_name}: {len(bin_data)} samples\")\n",
    "        print(f\"  Predicted hoax: {n_predicted}\")\n",
    "        print(f\"  Reclassified: {n_reclassified}\")\n",
    "\n",
    "# Channel distribution untuk hoax\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHANNEL DISTRIBUTION UNTUK HOAX\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "hoax_channels = hoax_subset['channel'].value_counts().head(15)\n",
    "print(\"\\nTop 15 Channel dengan Hoax Terbanyak:\")\n",
    "for idx, (channel, count) in enumerate(hoax_channels.items(), 1):\n",
    "    print(f\"  {idx:2d}. {channel}: {count} hoax\")\n",
    "\n",
    "# Channel distribution untuk valid\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHANNEL DISTRIBUTION UNTUK VALID\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "valid_subset = df_balanced[df_balanced['predicted_label_str'] == 'valid']\n",
    "valid_channels = valid_subset['channel'].value_counts().head(10)\n",
    "\n",
    "print(\"\\nTop 10 Channel Valid:\")\n",
    "for idx, (channel, count) in enumerate(valid_channels.items(), 1):\n",
    "    print(f\"  {idx:2d}. {channel}: {count} valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e666f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REVIEW SAMPLE PSEUDO-LABELS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "BAGIAN 1: SAMPLE HOAX (10 samples dari berbagai range)\n",
      "================================================================================\n",
      "\n",
      "1. [PREDICTED] [YT_00035]\n",
      "   Title: Wapres Gibran Tunaikan Sholat Ied Idul Fitri dan Bersilaturahmi Dengan Presiden...\n",
      "   Channel: Wakil Presiden Republik Indonesia\n",
      "   Label: HOAX | Confidence: 0.5572 (55.72%)\n",
      "   Prob [Hoax|Valid]: [0.5572|0.4428]\n",
      "\n",
      "2. [PREDICTED] [YT_00261]\n",
      "   Title: Respons China soal Pertemuan Trump dengan PM Jepang Sanae Takaichi...\n",
      "   Channel: Kompas.com\n",
      "   Label: HOAX | Confidence: 0.5227 (52.27%)\n",
      "   Prob [Hoax|Valid]: [0.5227|0.4773]\n",
      "\n",
      "3. [PREDICTED] [YT_00295]\n",
      "   Title: Violence sweeps across Indonesia amid protests over worsening economy...\n",
      "   Channel: PBS NewsHour\n",
      "   Label: HOAX | Confidence: 0.5799 (57.99%)\n",
      "   Prob [Hoax|Valid]: [0.5799|0.4201]\n",
      "\n",
      "4. [PREDICTED] [YT_00011]\n",
      "   Title: Mengapa Presiden Prabowo Selalu Pilih Kader Gerindra dalam Reshuffle Kabinet?...\n",
      "   Channel: Kompas.com\n",
      "   Label: HOAX | Confidence: 0.6828 (68.28%)\n",
      "   Prob [Hoax|Valid]: [0.6828|0.3172]\n",
      "\n",
      "5. [PREDICTED] [YT_00842]\n",
      "   Title: Kinerja Pemerintahan Prabowo - Gibran 1 Tahun Pertama | Primetime News...\n",
      "   Channel: METRO TV \n",
      "   Label: HOAX | Confidence: 0.6181 (61.81%)\n",
      "   Prob [Hoax|Valid]: [0.6181|0.3819]\n",
      "\n",
      "6. [RECLASSIFIED] [YT_01522]\n",
      "   Title: Detik-detik Prabowo Tinggalkan Indonesia Hadiri KTT ASEAN di Malaysia, Sempat Beri Arahan ...\n",
      "   Channel: Tribunnews\n",
      "   Label: HOAX | Confidence: 0.6026 (60.26%)\n",
      "   Prob [Hoax|Valid]: [0.3974|0.6026]\n",
      "\n",
      "7. [RECLASSIFIED] [YT_01337]\n",
      "   Title: Kantor Menkeu Purbaya Digeruduk Belasan Gubernur Buntut Pemotongan Anggaran ke Pemerintah ...\n",
      "   Channel: Tribunnews\n",
      "   Label: HOAX | Confidence: 0.6057 (60.57%)\n",
      "   Prob [Hoax|Valid]: [0.3943|0.6057]\n",
      "\n",
      "8. [PREDICTED] [YT_00039]\n",
      "   Title: Apakah Benar Jokowi Jadi Sekjen PBB 2026? | OneNews Update...\n",
      "   Channel: tvOneNews \n",
      "   Label: HOAX | Confidence: 0.7114 (71.14%)\n",
      "   Prob [Hoax|Valid]: [0.7114|0.2886]\n",
      "\n",
      "9. [PREDICTED] [YT_00046]\n",
      "   Title: Apakah Benar Jokowi Jadi Sekjen PBB 2026? | OneNews Update...\n",
      "   Channel: tvOneNews \n",
      "   Label: HOAX | Confidence: 0.7114 (71.14%)\n",
      "   Prob [Hoax|Valid]: [0.7114|0.2886]\n",
      "\n",
      "10. [PREDICTED] [YT_00132]\n",
      "   Title: Jaga Stabilitas Negara, Pemerintah Fokus Sistem Pertahanan Udara - [Metro Pagi Primetime]...\n",
      "   Channel: METRO TV \n",
      "   Label: HOAX | Confidence: 0.7104 (71.04%)\n",
      "   Prob [Hoax|Valid]: [0.7104|0.2896]\n",
      "\n",
      "================================================================================\n",
      "BAGIAN 2: SAMPLE VALID HIGH-CONFIDENCE (5 samples)\n",
      "================================================================================\n",
      "\n",
      "1. [YT_00441]\n",
      "   Title: Dana Asing Mengalir Deras ke IHSG Sepanjang Oktober 2025 | 2ND SESSION CLOSING...\n",
      "   Channel: IDX CHANNEL\n",
      "   Label: VALID | Confidence: 0.9949 (99.49%)\n",
      "   Prob [Hoax|Valid]: [0.0051|0.9949]\n",
      "\n",
      "2. [YT_01152]\n",
      "   Title: Komisi I DPR RI: Pertahanan Wilayah 3T Kunci Keamanan Nasional - TVR 120...\n",
      "   Channel: TVR PARLEMEN\n",
      "   Label: VALID | Confidence: 0.9925 (99.25%)\n",
      "   Prob [Hoax|Valid]: [0.0075|0.9925]\n",
      "\n",
      "3. [YT_00458]\n",
      "   Title: PROFIL DAN HARTA KEKAYAAN GUBERNUR RIAU YANG KENA OTT KPK DI PEKANBARU...\n",
      "   Channel: Tribun Pontianak\n",
      "   Label: VALID | Confidence: 0.9922 (99.22%)\n",
      "   Prob [Hoax|Valid]: [0.0078|0.9922]\n",
      "\n",
      "4. [YT_01315]\n",
      "   Title: Pemerintah Hadir Bukan Sekadar Janji, tapi Aksi Nyata untuk Rakyat....\n",
      "   Channel: Kemensos RI\n",
      "   Label: VALID | Confidence: 0.9920 (99.20%)\n",
      "   Prob [Hoax|Valid]: [0.0080|0.9920]\n",
      "\n",
      "5. [YT_00258]\n",
      "   Title: ASEAN Summit 2025: Trump and Asia Pacific Leaders Meet in Malaysia...\n",
      "   Channel: moneycontrol\n",
      "   Label: VALID | Confidence: 0.9920 (99.20%)\n",
      "   Prob [Hoax|Valid]: [0.0080|0.9920]\n",
      "\n",
      "================================================================================\n",
      "BAGIAN 3: HOAX DENGAN CONFIDENCE TERENDAH (Butuh Manual Review)\n",
      "================================================================================\n",
      "\n",
      "5 Hoax dengan confidence terendah (rekomendasi untuk manual review):\n",
      "\n",
      "1. [PREDICTED] Confidence: 0.5027\n",
      "   ID: YT_00839\n",
      "   Title: GANTI HALUAN? PROJO Tak Lagi Dukung Gibran & Sebut Cuma akan Sukseskan Prabowo di Pilpres 2029\n",
      "   Channel: Harian Surya\n",
      "   Prob [Hoax|Valid]: [0.5027|0.4973]\n",
      "\n",
      "2. [PREDICTED] Confidence: 0.5029\n",
      "   ID: YT_00675\n",
      "   Title: Kegelisahan Jokowi:  Dinasti Politik  dan Isu Ijazah Palsu\n",
      "   Channel: Veritas Aktual\n",
      "   Prob [Hoax|Valid]: [0.5029|0.4971]\n",
      "\n",
      "3. [RECLASSIFIED] Confidence: 0.5100\n",
      "   ID: YT_00593\n",
      "   Title: [HEADLINE NEWS 09/09] Ustaz Khalid Basalamah Diperiksa KPK Soal Dugaan Korupsi Kuota Haji\n",
      "   Channel: METRO TV \n",
      "   Prob [Hoax|Valid]: [0.4900|0.5100]\n",
      "\n",
      "4. [PREDICTED] Confidence: 0.5113\n",
      "   ID: YT_00526\n",
      "   Title: Prabowo Reshuffle dan Lantik 5 Menteri Kabinet Merah Putih\n",
      "   Channel: Media Indonesia\n",
      "   Prob [Hoax|Valid]: [0.5113|0.4887]\n",
      "\n",
      "5. [RECLASSIFIED] Confidence: 0.5121\n",
      "   ID: YT_00416\n",
      "   Title: Keamanan Suatu Negara: Fondasi Kedaulatan dan Pertahanan Nasional Indonesia\n",
      "   Channel:  786,FactPulse\n",
      "   Prob [Hoax|Valid]: [0.4879|0.5121]\n",
      "\n",
      "================================================================================\n",
      "BAGIAN 4: SAMPLE RECLASSIFIED (5 contoh)\n",
      "================================================================================\n",
      "\n",
      "5 Borderline valid yang di-reclassify jadi hoax:\n",
      "\n",
      "1. [YT_00593] Conf: 0.5100\n",
      "   Title: [HEADLINE NEWS 09/09] Ustaz Khalid Basalamah Diperiksa KPK Soal Dugaan Korupsi Kuota Haji\n",
      "   Channel: METRO TV \n",
      "   Prob [Hoax|Valid]: [0.4900|0.5100]\n",
      "\n",
      "2. [YT_00416] Conf: 0.5121\n",
      "   Title: Keamanan Suatu Negara: Fondasi Kedaulatan dan Pertahanan Nasional Indonesia\n",
      "   Channel:  786,FactPulse\n",
      "   Prob [Hoax|Valid]: [0.4879|0.5121]\n",
      "\n",
      "3. [YT_01018] Conf: 0.5241\n",
      "   Title: Informasi Permohonan Izin Besuk Tahanan Pada Pengadilan Negeri Negara menggunakan Aplikasi E-Berpadu\n",
      "   Channel: Pengadilan Negeri Negara\n",
      "   Prob [Hoax|Valid]: [0.4759|0.5241]\n",
      "\n",
      "4. [YT_00609] Conf: 0.5437\n",
      "   Title: BIKIN TERANG DUGAAN PATGULIPAT KERETA CEPAT, SIAPA YANG SALAH?\n",
      "   Channel: Official iNews\n",
      "   Prob [Hoax|Valid]: [0.4563|0.5437]\n",
      "\n",
      "5. [YT_00363] Conf: 0.5490\n",
      "   Title: Prabowo's 'Red and White' cabinet is Indonesia's largest since 1960s\n",
      "   Channel: CNA\n",
      "   Prob [Hoax|Valid]: [0.4510|0.5490]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REVIEW SAMPLE PSEUDO-LABELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# BAGIAN 1: Sample hoax dari berbagai range\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BAGIAN 1: SAMPLE HOAX (10 samples dari berbagai range)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "hoax_samples = df_balanced[df_balanced['predicted_label_str'] == 'hoax'].copy()\n",
    "\n",
    "# Ambil sample dari berbagai confidence range\n",
    "sample_low = hoax_samples[hoax_samples['conf_bin'] == '0.50-0.60'].head(3)\n",
    "sample_mid = hoax_samples[hoax_samples['conf_bin'] == '0.60-0.70'].head(4)\n",
    "sample_high = hoax_samples[hoax_samples['conf_bin'] == '0.70-0.80'].head(3)\n",
    "\n",
    "hoax_review = pd.concat([sample_low, sample_mid, sample_high])\n",
    "\n",
    "for idx, (i, row) in enumerate(hoax_review.iterrows(), 1):\n",
    "    source_mark = \"[RECLASSIFIED]\" if row['source_type'] == 'reclassified' else \"[PREDICTED]\"\n",
    "    \n",
    "    print(f\"\\n{idx}. {source_mark} [{row['sample_id']}]\")\n",
    "    print(f\"   Title: {row['title'][:90]}...\")\n",
    "    print(f\"   Channel: {row['channel']}\")\n",
    "    print(f\"   Label: HOAX | Confidence: {row['confidence']:.4f} ({row['confidence']*100:.2f}%)\")\n",
    "    print(f\"   Prob [Hoax|Valid]: [{row['prob_hoax']:.4f}|{row['prob_valid']:.4f}]\")\n",
    "\n",
    "# BAGIAN 2: Sample valid high-confidence\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BAGIAN 2: SAMPLE VALID HIGH-CONFIDENCE (5 samples)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "valid_samples = df_balanced[\n",
    "    df_balanced['predicted_label_str'] == 'valid'\n",
    "].nlargest(5, 'confidence')\n",
    "\n",
    "for idx, (i, row) in enumerate(valid_samples.iterrows(), 1):\n",
    "    print(f\"\\n{idx}. [{row['sample_id']}]\")\n",
    "    print(f\"   Title: {row['title'][:90]}...\")\n",
    "    print(f\"   Channel: {row['channel']}\")\n",
    "    print(f\"   Label: VALID | Confidence: {row['confidence']:.4f} ({row['confidence']*100:.2f}%)\")\n",
    "    print(f\"   Prob [Hoax|Valid]: [{row['prob_hoax']:.4f}|{row['prob_valid']:.4f}]\")\n",
    "\n",
    "# BAGIAN 3: Hoax dengan confidence terendah (butuh review)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BAGIAN 3: HOAX DENGAN CONFIDENCE TERENDAH (Butuh Manual Review)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "low_conf_hoax = hoax_samples.nsmallest(5, 'confidence')\n",
    "\n",
    "print(\"\\n5 Hoax dengan confidence terendah (rekomendasi untuk manual review):\")\n",
    "\n",
    "for idx, (i, row) in enumerate(low_conf_hoax.iterrows(), 1):\n",
    "    source_mark = \"[RECLASSIFIED]\" if row['source_type'] == 'reclassified' else \"[PREDICTED]\"\n",
    "    \n",
    "    print(f\"\\n{idx}. {source_mark} Confidence: {row['confidence']:.4f}\")\n",
    "    print(f\"   ID: {row['sample_id']}\")\n",
    "    print(f\"   Title: {row['title']}\")\n",
    "    print(f\"   Channel: {row['channel']}\")\n",
    "    print(f\"   Prob [Hoax|Valid]: [{row['prob_hoax']:.4f}|{row['prob_valid']:.4f}]\")\n",
    "\n",
    "# BAGIAN 4: Reclassified samples review\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BAGIAN 4: SAMPLE RECLASSIFIED (5 contoh)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "reclassified_samples = df_balanced[\n",
    "    df_balanced['source_type'] == 'reclassified'\n",
    "].head(5)\n",
    "\n",
    "print(\"\\n5 Borderline valid yang di-reclassify jadi hoax:\")\n",
    "\n",
    "for idx, (i, row) in enumerate(reclassified_samples.iterrows(), 1):\n",
    "    print(f\"\\n{idx}. [{row['sample_id']}] Conf: {row['confidence']:.4f}\")\n",
    "    print(f\"   Title: {row['title']}\")\n",
    "    print(f\"   Channel: {row['channel']}\")\n",
    "    print(f\"   Prob [Hoax|Valid]: [{row['prob_hoax']:.4f}|{row['prob_valid']:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6422e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPORT HASIL PSEUDO-LABELING\n",
      "================================================================================\n",
      "\n",
      "Path output:\n",
      "  Directory: D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\data\\training\n",
      "  CSV: youtube_pseudo_labeled_balanced.csv\n",
      "  JSON: youtube_pseudo_labeled_balanced.json\n",
      "\n",
      "Data berhasil diekspor ke CSV\n",
      "Backup JSON berhasil dibuat\n",
      "\n",
      "================================================================================\n",
      "SUMMARY EXPORT\n",
      "================================================================================\n",
      "\n",
      "Total records: 208\n",
      "\n",
      "Distribusi pseudo-label:\n",
      "  valid: 156 (75.0%)\n",
      "  hoax: 52 (25.0%)\n",
      "\n",
      "Distribusi confidence range:\n",
      "  0.50-0.60: 22\n",
      "  0.60-0.70: 22\n",
      "  0.70-0.80: 6\n",
      "  0.80-0.90: 1\n",
      "  0.90-0.95: 1\n",
      "  0.95-1.00: 156\n",
      "\n",
      "Distribusi labeling source:\n",
      "  high_confidence: 156 (75.0%)\n",
      "  reclassified: 31 (14.9%)\n",
      "  predicted_hoax: 21 (10.1%)\n",
      "\n",
      "================================================================================\n",
      "STATISTIK CONFIDENCE PER LABEL\n",
      "================================================================================\n",
      "\n",
      "HOAX:\n",
      "  Count: 52\n",
      "  Mean: 0.6278\n",
      "  Median: 0.6285\n",
      "  Min: 0.5027\n",
      "  Max: 0.9056\n",
      "  Std Dev: 0.0859\n",
      "\n",
      "VALID:\n",
      "  Count: 156\n",
      "  Mean: 0.9860\n",
      "  Median: 0.9859\n",
      "  Min: 0.9813\n",
      "  Max: 0.9949\n",
      "  Std Dev: 0.0030\n",
      "\n",
      "================================================================================\n",
      "PSEUDO-LABELING SELESAI\n",
      "================================================================================\n",
      "\n",
      "File yang dihasilkan:\n",
      "  1. D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\data\\training/youtube_pseudo_labeled_balanced.csv\n",
      "  2. D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\data\\training/youtube_pseudo_labeled_balanced.json\n",
      "\n",
      "RINGKASAN AKHIR:\n",
      "  Total pseudo-labels: 208\n",
      "  Hoax: 52\n",
      "  Valid: 156\n",
      "  Ratio Valid:Hoax: 3.00:1\n",
      "  Avg confidence (Hoax): 0.6278\n",
      "  Avg confidence (Valid): 0.9860\n",
      "  Borderline reclassified: 31 (14.9%)\n",
      "\n",
      "================================================================================\n",
      "REKOMENDASI NEXT STEPS\n",
      "================================================================================\n",
      "\n",
      "1. Manual Review\n",
      "   Review 5 hoax dengan confidence terendah untuk quality assurance\n",
      "\n",
      "2. Integrasi Data\n",
      "   Gabungkan dengan data TBH dan News (original labeled data)\n",
      "\n",
      "3. Training Strategy\n",
      "   - Gunakan curriculum learning (high-conf dulu, lalu semua data)\n",
      "   - Apply weighted loss berdasarkan pseudo_confidence\n",
      "   - Sample weight = confidence^2 untuk pseudo-labels\n",
      "\n",
      "4. Evaluation\n",
      "   - 5-fold stratified cross-validation\n",
      "   - Monitor F1-score untuk hoax class (minority)\n",
      "   - Tune threshold untuk optimal precision-recall\n",
      "\n",
      "5. Expected Performance\n",
      "   - Overall accuracy: 83-87%\n",
      "   - Hoax F1-score: 0.75-0.80\n",
      "   - ROC-AUC: 0.86-0.90\n",
      "\n",
      "================================================================================\n",
      "PSEUDO-LABELING BERHASIL DISELESAIKAN\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORT HASIL PSEUDO-LABELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Pilih kolom penting untuk export\n",
    "output_columns = [\n",
    "    'sample_id', 'source', 'keyword', 'video_id',\n",
    "    'title', 'channel', 'duration', 'upload_date',\n",
    "    'url', 'audio_path', 'thumbnail_path',\n",
    "    'transcript_path', 'transcript_text', 'transcript_length',\n",
    "    'normalized_text', 'token_count',\n",
    "    'predicted_label_str', 'confidence',\n",
    "    'prob_hoax', 'prob_valid',\n",
    "    'conf_bin', 'source_type'\n",
    "]\n",
    "\n",
    "df_export = df_balanced[output_columns].copy()\n",
    "\n",
    "# Rename kolom untuk clarity\n",
    "df_export = df_export.rename(columns={\n",
    "    'predicted_label_str': 'pseudo_label',\n",
    "    'confidence': 'pseudo_confidence',\n",
    "    'conf_bin': 'confidence_range',\n",
    "    'source_type': 'labeling_source'\n",
    "})\n",
    "\n",
    "# Sort by pseudo_label dan confidence\n",
    "df_export = df_export.sort_values(\n",
    "    ['pseudo_label', 'pseudo_confidence'],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# Path output (sesuaikan dengan folder Anda)\n",
    "output_dir = r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\data\\training'\n",
    "output_csv = f'{output_dir}/youtube_pseudo_labeled_balanced.csv'\n",
    "output_json = f'{output_dir}/youtube_pseudo_labeled_balanced.json'\n",
    "\n",
    "print(f\"\\nPath output:\")\n",
    "print(f\"  Directory: {output_dir}\")\n",
    "print(f\"  CSV: youtube_pseudo_labeled_balanced.csv\")\n",
    "print(f\"  JSON: youtube_pseudo_labeled_balanced.json\")\n",
    "\n",
    "# Export ke CSV\n",
    "df_export.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "print(f\"\\nData berhasil diekspor ke CSV\")\n",
    "\n",
    "# Export ke JSON\n",
    "df_export.to_json(output_json, orient='records', indent=2, force_ascii=False)\n",
    "print(f\"Backup JSON berhasil dibuat\")\n",
    "\n",
    "# Summary export\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY EXPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal records: {len(df_export)}\")\n",
    "\n",
    "print(f\"\\nDistribusi pseudo-label:\")\n",
    "label_dist = df_export['pseudo_label'].value_counts()\n",
    "for label, count in label_dist.items():\n",
    "    pct = count / len(df_export) * 100\n",
    "    print(f\"  {label}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribusi confidence range:\")\n",
    "conf_dist = df_export['confidence_range'].value_counts().sort_index()\n",
    "for range_name, count in conf_dist.items():\n",
    "    print(f\"  {range_name}: {count}\")\n",
    "\n",
    "print(f\"\\nDistribusi labeling source:\")\n",
    "source_dist = df_export['labeling_source'].value_counts()\n",
    "for source, count in source_dist.items():\n",
    "    pct = count / len(df_export) * 100\n",
    "    print(f\"  {source}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Statistik confidence per label\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTIK CONFIDENCE PER LABEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for label in ['hoax', 'valid']:\n",
    "    subset = df_export[df_export['pseudo_label'] == label]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{label.upper()}:\")\n",
    "        print(f\"  Count: {len(subset)}\")\n",
    "        print(f\"  Mean: {subset['pseudo_confidence'].mean():.4f}\")\n",
    "        print(f\"  Median: {subset['pseudo_confidence'].median():.4f}\")\n",
    "        print(f\"  Min: {subset['pseudo_confidence'].min():.4f}\")\n",
    "        print(f\"  Max: {subset['pseudo_confidence'].max():.4f}\")\n",
    "        print(f\"  Std Dev: {subset['pseudo_confidence'].std():.4f}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PSEUDO-LABELING SELESAI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nFile yang dihasilkan:\")\n",
    "print(f\"  1. {output_csv}\")\n",
    "print(f\"  2. {output_json}\")\n",
    "\n",
    "print(f\"\\nRINGKASAN AKHIR:\")\n",
    "print(f\"  Total pseudo-labels: {len(df_export)}\")\n",
    "print(f\"  Hoax: {(df_export['pseudo_label']=='hoax').sum()}\")\n",
    "print(f\"  Valid: {(df_export['pseudo_label']=='valid').sum()}\")\n",
    "\n",
    "if 'hoax' in label_dist.index and 'valid' in label_dist.index:\n",
    "    ratio = label_dist['valid'] / label_dist['hoax']\n",
    "    print(f\"  Ratio Valid:Hoax: {ratio:.2f}:1\")\n",
    "\n",
    "print(f\"  Avg confidence (Hoax): {df_export[df_export['pseudo_label']=='hoax']['pseudo_confidence'].mean():.4f}\")\n",
    "print(f\"  Avg confidence (Valid): {df_export[df_export['pseudo_label']=='valid']['pseudo_confidence'].mean():.4f}\")\n",
    "\n",
    "n_reclassified = (df_export['labeling_source'] == 'reclassified').sum()\n",
    "print(f\"  Borderline reclassified: {n_reclassified} ({n_reclassified/len(df_export)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REKOMENDASI NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Manual Review\")\n",
    "print(\"   Review 5 hoax dengan confidence terendah untuk quality assurance\")\n",
    "\n",
    "print(\"\\n2. Integrasi Data\")\n",
    "print(\"   Gabungkan dengan data TBH dan News (original labeled data)\")\n",
    "\n",
    "print(\"\\n3. Training Strategy\")\n",
    "print(\"   - Gunakan curriculum learning (high-conf dulu, lalu semua data)\")\n",
    "print(\"   - Apply weighted loss berdasarkan pseudo_confidence\")\n",
    "print(\"   - Sample weight = confidence^2 untuk pseudo-labels\")\n",
    "\n",
    "print(\"\\n4. Evaluation\")\n",
    "print(\"   - 5-fold stratified cross-validation\")\n",
    "print(\"   - Monitor F1-score untuk hoax class (minority)\")\n",
    "print(\"   - Tune threshold untuk optimal precision-recall\")\n",
    "\n",
    "print(\"\\n5. Expected Performance\")\n",
    "print(\"   - Overall accuracy: 83-87%\")\n",
    "print(\"   - Hoax F1-score: 0.75-0.80\")\n",
    "print(\"   - ROC-AUC: 0.86-0.90\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PSEUDO-LABELING BERHASIL DISELESAIKAN\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8607f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERSIAPAN DATA TRAINING (TANPA MANUAL REVIEW)\n",
      "================================================================================\n",
      "\n",
      "Dataset final:\n",
      "  Total samples: 208\n",
      "  Hoax: 52\n",
      "  Valid: 156\n",
      "\n",
      "Sample weight statistics:\n",
      "  Min weight: 0.2527\n",
      "  Max weight: 0.9899\n",
      "  Mean weight: 0.8294\n",
      "\n",
      "Hoax samples weight distribution:\n",
      "  Mean: 0.4014\n",
      "  Min: 0.2527\n",
      "  Max: 0.8202\n",
      "\n",
      "Valid samples weight distribution:\n",
      "  Mean: 0.9721\n",
      "  Min: 0.9630\n",
      "  Max: 0.9899\n",
      "\n",
      "================================================================================\n",
      "DATASET SIAP UNTUK TRAINING\n",
      "================================================================================\n",
      "\n",
      "Note:\n",
      "  - Low-confidence samples (0.50-0.60) punya weight rendah (0.25-0.36)\n",
      "  - High-confidence samples (0.98-0.99) punya weight tinggi (0.96-0.98)\n",
      "  - Model otomatis belajar lebih dari high-confidence samples\n",
      "  - Noise dari borderline cases diminimalkan\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERSIAPAN DATA TRAINING (TANPA MANUAL REVIEW)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Gunakan semua data dengan weighted loss\n",
    "df_final = df_export.copy()\n",
    "\n",
    "# Calculate sample weights (confidence^2)\n",
    "df_final['sample_weight'] = df_final['pseudo_confidence'] ** 2\n",
    "\n",
    "print(f\"\\nDataset final:\")\n",
    "print(f\"  Total samples: {len(df_final)}\")\n",
    "print(f\"  Hoax: {(df_final['pseudo_label']=='hoax').sum()}\")\n",
    "print(f\"  Valid: {(df_final['pseudo_label']=='valid').sum()}\")\n",
    "\n",
    "print(f\"\\nSample weight statistics:\")\n",
    "print(f\"  Min weight: {df_final['sample_weight'].min():.4f}\")\n",
    "print(f\"  Max weight: {df_final['sample_weight'].max():.4f}\")\n",
    "print(f\"  Mean weight: {df_final['sample_weight'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nHoax samples weight distribution:\")\n",
    "hoax_weights = df_final[df_final['pseudo_label']=='hoax']['sample_weight']\n",
    "print(f\"  Mean: {hoax_weights.mean():.4f}\")\n",
    "print(f\"  Min: {hoax_weights.min():.4f}\")\n",
    "print(f\"  Max: {hoax_weights.max():.4f}\")\n",
    "\n",
    "print(f\"\\nValid samples weight distribution:\")\n",
    "valid_weights = df_final[df_final['pseudo_label']=='valid']['sample_weight']\n",
    "print(f\"  Mean: {valid_weights.mean():.4f}\")\n",
    "print(f\"  Min: {valid_weights.min():.4f}\")\n",
    "print(f\"  Max: {valid_weights.max():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASET SIAP UNTUK TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote:\")\n",
    "print(\"  - Low-confidence samples (0.50-0.60) punya weight rendah (0.25-0.36)\")\n",
    "print(\"  - High-confidence samples (0.98-0.99) punya weight tinggi (0.96-0.98)\")\n",
    "print(\"  - Model otomatis belajar lebih dari high-confidence samples\")\n",
    "print(\"  - Noise dari borderline cases diminimalkan\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
