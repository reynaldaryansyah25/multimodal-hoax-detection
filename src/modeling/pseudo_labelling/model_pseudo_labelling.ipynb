{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811cf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semua library berhasil diimport\n",
      "Versi PyTorch: 2.9.1+cpu\n",
      "CUDA tersedia: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Semua library berhasil diimport\")\n",
    "print(f\"Versi PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA tersedia: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device GPU: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bdd1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 1: MEMUAT DAN EKSPLORASI DATA\n",
      "================================================================================\n",
      "\n",
      "Jumlah data: 3,068 baris\n",
      "Jumlah kolom: 12\n",
      "\n",
      "Nama kolom:\n",
      "['id', 'url', 'domain', 'date', 'title', 'text', 'source_type', 'dataset_origin', 'fp_new', 'label', 'label_str', 'text_clean']\n",
      "\n",
      "Contoh data:\n",
      "                                               title label_str source_type\n",
      "0  Profil Menko Hukum HAM Yusril Ihza Mahendra di...     valid        news\n",
      "1  Profil Menteri PPPA Arifatul Choiri Fauzi di K...     valid        news\n",
      "2  Prabowo Tunjuk Yassierli Jadi Menteri Ketenaga...     valid        news\n",
      "3  Profil Yassierli, Menteri Ketenagakerjaan Kabi...     valid        news\n",
      "4  Apa yang Harus Dilakukan di Usia 30 Tahun untu...     valid        news\n",
      "\n",
      "Distribusi label:\n",
      "label_str\n",
      "valid    1895\n",
      "hoax     1173\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 1: MEMUAT DAN EKSPLORASI DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Baca dataset\n",
    "df = pd.read_csv('D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\data\\processed\\dataset_clean_finalv1.csv')\n",
    "print(f\"\\nJumlah data: {len(df):,} baris\")\n",
    "print(f\"Jumlah kolom: {len(df.columns)}\")\n",
    "\n",
    "# Tampilkan kolom\n",
    "print(f\"\\nNama kolom:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Tampilkan 5 data pertama\n",
    "print(\"\\nContoh data:\")\n",
    "print(df[['title', 'label_str', 'source_type']].head())\n",
    "\n",
    "# Distribusi label\n",
    "print(\"\\nDistribusi label:\")\n",
    "print(df['label_str'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 2: PEMBERSIHAN DATA\n",
      "================================================================================\n",
      "\n",
      "Membersihkan data...\n",
      "Ukuran awal: 3,068 baris\n",
      "Setelah dibersihkan: 3,067 baris\n",
      "Data yang dihapus: 1 baris\n",
      "\n",
      "Statistik jumlah kata pada title:\n",
      "Valid - Rata-rata: 10.4 kata\n",
      "Hoax  - Rata-rata: 8.4 kata\n",
      "\n",
      "Contoh title per kategori:\n",
      "\n",
      "VALID:\n",
      "  - difoto pakai kamera android, ariel noah: beda banget experience-nya\n",
      "  - kronologi bripka anditya gugur di pantai pangandaran saat tolong wisatawan, diberi kenaikan pangkat\n",
      "\n",
      "HOAX:\n",
      "  - jokowi dan luhut terima uang rp4,5 t dari nadiem makarim\n",
      "  - eksploitasi peristiwa pembakaran gedung bawaslu\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 2: PEMBERSIHAN DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Gunakan title sebagai fitur\n",
    "df['title_clean'] = df['title'].str.lower().str.strip()\n",
    "\n",
    "# Hapus data kosong dan duplikat\n",
    "print(\"\\nMembersihkan data...\")\n",
    "ukuran_awal = len(df)\n",
    "\n",
    "df = df.dropna(subset=['title_clean'])\n",
    "df['jumlah_kata'] = df['title_clean'].str.split().str.len()\n",
    "df = df[df['jumlah_kata'] >= 3]\n",
    "df = df.drop_duplicates(subset=['title_clean'])\n",
    "\n",
    "print(f\"Ukuran awal: {ukuran_awal:,} baris\")\n",
    "print(f\"Setelah dibersihkan: {len(df):,} baris\")\n",
    "print(f\"Data yang dihapus: {ukuran_awal - len(df):,} baris\")\n",
    "\n",
    "# Statistik title\n",
    "print(\"\\nStatistik jumlah kata pada title:\")\n",
    "print(f\"Valid - Rata-rata: {df[df['label_str']=='valid']['jumlah_kata'].mean():.1f} kata\")\n",
    "print(f\"Hoax  - Rata-rata: {df[df['label_str']=='hoax']['jumlah_kata'].mean():.1f} kata\")\n",
    "\n",
    "# Contoh title\n",
    "print(\"\\nContoh title per kategori:\")\n",
    "for label in ['valid', 'hoax']:\n",
    "    print(f\"\\n{label.upper()}:\")\n",
    "    sampel = df[df['label_str']==label].sample(2, random_state=42)\n",
    "    for idx, row in sampel.iterrows():\n",
    "        print(f\"  - {row['title_clean']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b5545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 3: SPLIT DATA TRAINING DAN TESTING\n",
      "================================================================================\n",
      "\n",
      "Data training: 2,453 baris\n",
      "Data testing:  614 baris\n",
      "\n",
      "Distribusi label training:\n",
      "label_str\n",
      "valid    1515\n",
      "hoax      938\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribusi label testing:\n",
      "label_str\n",
      "valid    379\n",
      "hoax     235\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 3: SPLIT DATA TRAINING DAN TESTING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Split stratified\n",
    "train_df, test_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    stratify=df['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nData training: {len(train_df):,} baris\")\n",
    "print(f\"Data testing:  {len(test_df):,} baris\")\n",
    "\n",
    "# Siapkan array\n",
    "X_train = train_df['title_clean'].values\n",
    "y_train = train_df['label'].values\n",
    "X_test = test_df['title_clean'].values\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Distribusi label\n",
    "print(\"\\nDistribusi label training:\")\n",
    "print(train_df['label_str'].value_counts())\n",
    "print(\"\\nDistribusi label testing:\")\n",
    "print(test_df['label_str'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431e5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 4: PEMBUATAN FITUR TF-IDF\n",
      "================================================================================\n",
      "\n",
      "Membuat fitur TF-IDF...\n",
      "Ukuran vocabulary: 3,000\n",
      "Dimensi training: (2453, 3000)\n",
      "Dimensi testing:  (614, 3000)\n",
      "\n",
      "10 fitur pertama:\n",
      "  - 000\n",
      "  - 000 dapat\n",
      "  - 000 dapat berapa\n",
      "  - 10\n",
      "  - 10 juta\n",
      "  - 10 persen\n",
      "  - 10 tahun\n",
      "  - 100\n",
      "  - 100 hari\n",
      "  - 11\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 4: PEMBUATAN FITUR TF-IDF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Inisialisasi TF-IDF\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=3000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=2,\n",
    "    max_df=0.7,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "# Transform data\n",
    "print(\"\\nMembuat fitur TF-IDF...\")\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"Ukuran vocabulary: {len(tfidf.vocabulary_):,}\")\n",
    "print(f\"Dimensi training: {X_train_tfidf.shape}\")\n",
    "print(f\"Dimensi testing:  {X_test_tfidf.shape}\")\n",
    "\n",
    "# Contoh fitur teratas\n",
    "fitur_nama = tfidf.get_feature_names_out()\n",
    "print(f\"\\n10 fitur pertama:\")\n",
    "for nama in fitur_nama[:10]:\n",
    "    print(f\"  - {nama}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8fa74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 5: PERHITUNGAN BOBOT KELAS\n",
      "================================================================================\n",
      "\n",
      "Bobot kelas:\n",
      "  Hoax (0):  1.3076\n",
      "  Valid (1): 0.8096\n",
      "\n",
      "Keterangan: Bobot lebih tinggi untuk kelas minoritas\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 5: PERHITUNGAN BOBOT KELAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Hitung bobot\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "print(\"\\nBobot kelas:\")\n",
    "print(f\"  Hoax (0):  {class_weight_dict[0]:.4f}\")\n",
    "print(f\"  Valid (1): {class_weight_dict[1]:.4f}\")\n",
    "print(\"\\nKeterangan: Bobot lebih tinggi untuk kelas minoritas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 6: TRAINING MODEL TF-IDF + LOGISTIC REGRESSION\n",
      "================================================================================\n",
      "\n",
      "Memulai training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training selesai\n",
      "Model tersimpan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 6: TRAINING MODEL TF-IDF + LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Inisialisasi model\n",
    "logreg = LogisticRegression(\n",
    "    class_weight=class_weight_dict,\n",
    "    max_iter=1000,\n",
    "    C=1.0,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Training\n",
    "print(\"\\nMemulai training...\")\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "print(\"Training selesai\")\n",
    "\n",
    "# Simpan model\n",
    "joblib.dump(tfidf, r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\pseudo_labelling\\tf-idf/tfidf_title_vectorizer.pkl')\n",
    "joblib.dump(logreg, r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\pseudo_labelling\\tf-idf/logreg_title_model.pkl')\n",
    "print(\"Model tersimpan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01814ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 6: TRAINING MODEL TF-IDF + LOGISTIC REGRESSION\n",
      "================================================================================\n",
      "\n",
      "Memulai training...\n",
      "Training selesai\n",
      "Model tersimpan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 6: TRAINING MODEL TF-IDF + LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Inisialisasi model\n",
    "logreg = LogisticRegression(\n",
    "    class_weight=class_weight_dict,\n",
    "    max_iter=1000,\n",
    "    C=1.0,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Training\n",
    "print(\"\\nMemulai training...\")\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "print(\"Training selesai\")\n",
    "\n",
    "# Simpan model\n",
    "joblib.dump(tfidf, r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\pseudo_labelling\\tf-idf/tfidf_title_vectorizer.pkl')\n",
    "joblib.dump(logreg, r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\pseudo_labelling\\tf-idf/logreg_title_model.pkl')\n",
    "print(\"Model tersimpan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba5f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 7: EVALUASI MODEL TF-IDF\n",
      "================================================================================\n",
      "\n",
      "METRIK PERFORMA:\n",
      "Accuracy:  0.8550\n",
      "F1-Score:  0.8556\n",
      "AUC-ROC:   0.9360\n",
      "\n",
      "LAPORAN KLASIFIKASI:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hoax       0.80      0.83      0.81       235\n",
      "       valid       0.89      0.87      0.88       379\n",
      "\n",
      "    accuracy                           0.86       614\n",
      "   macro avg       0.85      0.85      0.85       614\n",
      "weighted avg       0.86      0.86      0.86       614\n",
      "\n",
      "\n",
      "MATRIKS KONFUSI:\n",
      "[[196  39]\n",
      " [ 50 329]]\n",
      "\n",
      "True Negative:  196\n",
      "False Positive: 39\n",
      "False Negative: 50\n",
      "True Positive:  329\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 7: EVALUASI MODEL TF-IDF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_tfidf = logreg.predict(X_test_tfidf)\n",
    "y_proba_tfidf = logreg.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Metrik\n",
    "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "f1_tfidf = f1_score(y_test, y_pred_tfidf, average='weighted')\n",
    "auc_tfidf = roc_auc_score(y_test, y_proba_tfidf)\n",
    "\n",
    "print(\"\\nMETRIK PERFORMA:\")\n",
    "print(f\"Accuracy:  {acc_tfidf:.4f}\")\n",
    "print(f\"F1-Score:  {f1_tfidf:.4f}\")\n",
    "print(f\"AUC-ROC:   {auc_tfidf:.4f}\")\n",
    "\n",
    "print(\"\\nLAPORAN KLASIFIKASI:\")\n",
    "print(classification_report(y_test, y_pred_tfidf, target_names=['hoax', 'valid']))\n",
    "\n",
    "print(\"\\nMATRIKS KONFUSI:\")\n",
    "cm_tfidf = confusion_matrix(y_test, y_pred_tfidf)\n",
    "print(cm_tfidf)\n",
    "print(f\"\\nTrue Negative:  {cm_tfidf[0,0]}\")\n",
    "print(f\"False Positive: {cm_tfidf[0,1]}\")\n",
    "print(f\"False Negative: {cm_tfidf[1,0]}\")\n",
    "print(f\"True Positive:  {cm_tfidf[1,1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916b272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 8: MEMUAT MODEL INDOBERT\n",
      "================================================================================\n",
      "\n",
      "Memuat indolem/indobert-base-uncased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndoBERT berhasil dimuat\n",
      "Jumlah parameter model: 110,559,746\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 8: MEMUAT MODEL INDOBERT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load model\n",
    "model_name = \"indolem/indobert-base-uncased\"\n",
    "print(f\"\\nMemuat {model_name}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "print(\"IndoBERT berhasil dimuat\")\n",
    "print(f\"Jumlah parameter model: {model.num_parameters():,}\")\n",
    "\n",
    "# Pindahkan model ke GPU jika tersedia\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    print(\"Model dipindahkan ke GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f29a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 9: TOKENISASI DATA\n",
      "================================================================================\n",
      "\n",
      "Memulai tokenisasi...\n",
      "Tokenisasi training selesai\n",
      "Tokenisasi testing selesai\n",
      "\n",
      "Panjang maksimum sequence: 64 token\n",
      "Ukuran vocabulary: 31923\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 9: TOKENISASI DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nMemulai tokenisasi...\")\n",
    "\n",
    "# Tokenisasi\n",
    "train_encodings = tokenizer(\n",
    "    train_df['title_clean'].tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=64\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    test_df['title_clean'].tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=64\n",
    ")\n",
    "\n",
    "print(\"Tokenisasi training selesai\")\n",
    "print(\"Tokenisasi testing selesai\")\n",
    "print(f\"\\nPanjang maksimum sequence: 64 token\")\n",
    "print(f\"Ukuran vocabulary: {len(tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87542c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 10: PEMBUATAN PYTORCH DATASET\n",
      "================================================================================\n",
      "Dataset training: 2453 sampel\n",
      "Dataset testing:  614 sampel\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 10: PEMBUATAN PYTORCH DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class HoaxDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Buat dataset\n",
    "train_dataset = HoaxDataset(train_encodings, train_df['label'].tolist())\n",
    "test_dataset = HoaxDataset(test_encodings, test_df['label'].tolist())\n",
    "\n",
    "print(f\"Dataset training: {len(train_dataset)} sampel\")\n",
    "print(f\"Dataset testing:  {len(test_dataset)} sampel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86a5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 11: DEFINISI CUSTOM TRAINER\n",
      "================================================================================\n",
      "Custom Trainer berhasil didefinisikan\n",
      "Bobot kelas akan diterapkan saat training\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 11: DEFINISI CUSTOM TRAINER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Loss dengan bobot kelas\n",
    "        class_weights_tensor = torch.tensor(\n",
    "            [class_weights[0], class_weights[1]], \n",
    "            dtype=torch.float\n",
    "        ).to(logits.device)\n",
    "        \n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "print(\"Custom Trainer berhasil didefinisikan\")\n",
    "print(\"Bobot kelas akan diterapkan saat training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61267ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 12: KONFIGURASI TRAINING\n",
      "================================================================================\n",
      "Konfigurasi training:\n",
      "  - Jumlah epoch: 5\n",
      "  - Ukuran batch: 32\n",
      "  - Learning rate: 3e-05\n",
      "  - Warmup steps: 200\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 12: KONFIGURASI TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=200,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_steps=50,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "print(\"Konfigurasi training:\")\n",
    "print(f\"  - Jumlah epoch: {training_args.num_train_epochs}\")\n",
    "print(f\"  - Ukuran batch: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  - Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  - Warmup steps: {training_args.warmup_steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ba1104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 13: TRAINING MODEL INDOBERT\n",
      "================================================================================\n",
      "\n",
      "PERINGATAN: Training akan memakan waktu 15-30 menit!\n",
      "Silakan tunggu hingga selesai...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='385' max='385' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [385/385 27:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.534900</td>\n",
       "      <td>0.478249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>0.305997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.313700</td>\n",
       "      <td>0.260053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.203931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.229814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training IndoBERT selesai\n",
      "Model tersimpan di folder 'indobert_title_model'\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 13: TRAINING MODEL INDOBERT\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nPERINGATAN: Training akan memakan waktu 15-30 menit!\")\n",
    "print(\"Silakan tunggu hingga selesai...\\n\")\n",
    "\n",
    "# Inisialisasi trainer\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Mulai training\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nTraining IndoBERT selesai\")\n",
    "\n",
    "# Simpan model\n",
    "model.save_pretrained(r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\pseudo_labelling/indobert_title_model')\n",
    "tokenizer.save_pretrained(r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\pseudo_labelling/indobert_title_model')\n",
    "print(\"Model tersimpan di folder 'indobert_title_model'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba6b72e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 14: EVALUASI MODEL INDOBERT\n",
      "================================================================================\n",
      "Model berada di device: cpu\n",
      "\n",
      "Memulai prediksi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:16<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRIK PERFORMA:\n",
      "Accuracy:  0.9349\n",
      "F1-Score:  0.9344\n",
      "\n",
      "LAPORAN KLASIFIKASI:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hoax       0.94      0.89      0.91       235\n",
      "       valid       0.93      0.97      0.95       379\n",
      "\n",
      "    accuracy                           0.93       614\n",
      "   macro avg       0.94      0.93      0.93       614\n",
      "weighted avg       0.94      0.93      0.93       614\n",
      "\n",
      "\n",
      "MATRIKS KONFUSI:\n",
      "[[208  27]\n",
      " [ 13 366]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 14: EVALUASI MODEL INDOBERT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Set ke mode evaluasi\n",
    "model.eval()\n",
    "\n",
    "# Pindahkan model ke device yang tepat\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"Model berada di device: {device}\")\n",
    "\n",
    "# Prediksi\n",
    "print(\"\\nMemulai prediksi...\")\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(X_test), 32)):\n",
    "        batch_texts = X_test[i:i+32].tolist()\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch_texts, \n",
    "            padding=True, \n",
    "            truncation=True,\n",
    "            max_length=64, \n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        batch_preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        predictions.extend(batch_preds)\n",
    "\n",
    "y_pred_bert = np.array(predictions)\n",
    "\n",
    "# Metrik\n",
    "acc_bert = accuracy_score(y_test, y_pred_bert)\n",
    "f1_bert = f1_score(y_test, y_pred_bert, average='weighted')\n",
    "\n",
    "print(\"\\nMETRIK PERFORMA:\")\n",
    "print(f\"Accuracy:  {acc_bert:.4f}\")\n",
    "print(f\"F1-Score:  {f1_bert:.4f}\")\n",
    "\n",
    "print(\"\\nLAPORAN KLASIFIKASI:\")\n",
    "print(classification_report(y_test, y_pred_bert, target_names=['hoax', 'valid']))\n",
    "\n",
    "print(\"\\nMATRIKS KONFUSI:\")\n",
    "cm_bert = confusion_matrix(y_test, y_pred_bert)\n",
    "print(cm_bert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf9d5343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAHAP 15: PERBANDINGAN MODEL\n",
      "================================================================================\n",
      "\n",
      "PERBANDINGAN AKHIR:\n",
      "          Model  Accuracy  F1-Score (Weighted)  F1-Score (Hoax)  F1-Score (Valid)\n",
      "TF-IDF + LogReg  0.855049             0.855639         0.814969          0.880857\n",
      "       IndoBERT  0.934853             0.934444         0.912281          0.948187\n",
      "\n",
      "MODEL TERBAIK: IndoBERT\n",
      "\n",
      "Hasil tersimpan di 'perbandingan_model.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TAHAP 15: PERBANDINGAN MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Buat tabel perbandingan\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['TF-IDF + LogReg', 'IndoBERT'],\n",
    "    'Accuracy': [acc_tfidf, acc_bert],\n",
    "    'F1-Score (Weighted)': [f1_tfidf, f1_bert],\n",
    "    'F1-Score (Hoax)': [\n",
    "        f1_score(y_test, y_pred_tfidf, average=None)[0],\n",
    "        f1_score(y_test, y_pred_bert, average=None)[0]\n",
    "    ],\n",
    "    'F1-Score (Valid)': [\n",
    "        f1_score(y_test, y_pred_tfidf, average=None)[1],\n",
    "        f1_score(y_test, y_pred_bert, average=None)[1]\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nPERBANDINGAN AKHIR:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Model terbaik\n",
    "best_model = comparison.loc[comparison['Accuracy'].idxmax(), 'Model']\n",
    "print(f\"\\nMODEL TERBAIK: {best_model}\")\n",
    "\n",
    "# Simpan hasil\n",
    "comparison.to_csv(r'D:\\INDONERIS-DATAMINING\\multimodal-hoax-detection\\models\\pseudo_labelling/perbandingan_model.csv', index=False)\n",
    "print(\"\\nHasil tersimpan di 'perbandingan_model.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
